{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d03ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d1f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc0d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import correlation, lr, perceptron, get_anova_dims, get_mi_dims\n",
    "from preparation import prepare_dataset, read_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7eb701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from we import get_we, initiate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ec8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4010b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3913b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a00518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2fae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert/camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'xlm-roberta-large',\n",
    "        'label': 'xlm_large'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'xlm-roberta-base', \n",
    "        'label': 'xlm_base'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-uncased',\n",
    "        'label': 'bert_base_u'\n",
    "    },\n",
    "    {\n",
    "        'name': 'distilbert-base-multilingual-cased',\n",
    "        'label': 'distilbert_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-cased',\n",
    "        'label': 'bert_base_c'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a923234",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [m['label'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac1a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_with_features = read_datasets(\n",
    "                            path = '../Data',\n",
    "                            model_labels = labels,\n",
    "                            file_name = 'all_nouns_we.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff77172b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Number</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Semantic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D</th>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.551025</td>\n",
       "      <td>0.347197</td>\n",
       "      <td>0.789782</td>\n",
       "      <td>0.393246</td>\n",
       "      <td>0.300031</td>\n",
       "      <td>0.609232</td>\n",
       "      <td>0.913722</td>\n",
       "      <td>0.178287</td>\n",
       "      <td>0.838988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586894</td>\n",
       "      <td>0.674134</td>\n",
       "      <td>0.276217</td>\n",
       "      <td>0.081619</td>\n",
       "      <td>0.154076</td>\n",
       "      <td>0.553278</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>2D</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>0.828946</td>\n",
       "      <td>0.549880</td>\n",
       "      <td>0.339958</td>\n",
       "      <td>0.797102</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.301288</td>\n",
       "      <td>0.603051</td>\n",
       "      <td>0.916539</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>0.844714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584636</td>\n",
       "      <td>0.674752</td>\n",
       "      <td>0.278596</td>\n",
       "      <td>0.078074</td>\n",
       "      <td>0.143366</td>\n",
       "      <td>0.548315</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>3D</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.826660</td>\n",
       "      <td>0.556389</td>\n",
       "      <td>0.332618</td>\n",
       "      <td>0.805891</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.295803</td>\n",
       "      <td>0.597985</td>\n",
       "      <td>0.914675</td>\n",
       "      <td>0.201301</td>\n",
       "      <td>0.846672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577705</td>\n",
       "      <td>0.673679</td>\n",
       "      <td>0.278649</td>\n",
       "      <td>0.081689</td>\n",
       "      <td>0.139490</td>\n",
       "      <td>0.533415</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>a</td>\n",
       "      <td>Attribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.826916</td>\n",
       "      <td>0.555891</td>\n",
       "      <td>0.332298</td>\n",
       "      <td>0.805754</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.296797</td>\n",
       "      <td>0.597758</td>\n",
       "      <td>0.914183</td>\n",
       "      <td>0.201098</td>\n",
       "      <td>0.845985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578594</td>\n",
       "      <td>0.673429</td>\n",
       "      <td>0.278861</td>\n",
       "      <td>0.081218</td>\n",
       "      <td>0.139010</td>\n",
       "      <td>0.533594</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aa</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.826281</td>\n",
       "      <td>0.556306</td>\n",
       "      <td>0.332007</td>\n",
       "      <td>0.805256</td>\n",
       "      <td>0.399368</td>\n",
       "      <td>0.296458</td>\n",
       "      <td>0.597567</td>\n",
       "      <td>0.914983</td>\n",
       "      <td>0.200809</td>\n",
       "      <td>0.846577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578808</td>\n",
       "      <td>0.673362</td>\n",
       "      <td>0.279152</td>\n",
       "      <td>0.081560</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>0.534123</td>\n",
       "      <td>singular</td>\n",
       "      <td>masculine</td>\n",
       "      <td>abandon</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "Word                                                                            \n",
       "2D       0.836139  0.551025  0.347197  0.789782  0.393246  0.300031  0.609232   \n",
       "3D       0.828946  0.549880  0.339958  0.797102  0.395346  0.301288  0.603051   \n",
       "a        0.826660  0.556389  0.332618  0.805891  0.399844  0.295803  0.597985   \n",
       "aa       0.826916  0.555891  0.332298  0.805754  0.400046  0.296797  0.597758   \n",
       "abandon  0.826281  0.556306  0.332007  0.805256  0.399368  0.296458  0.597567   \n",
       "\n",
       "                7         8         9  ...       762       763       764  \\\n",
       "Word                                   ...                                 \n",
       "2D       0.913722  0.178287  0.838988  ...  0.586894  0.674134  0.276217   \n",
       "3D       0.916539  0.185836  0.844714  ...  0.584636  0.674752  0.278596   \n",
       "a        0.914675  0.201301  0.846672  ...  0.577705  0.673679  0.278649   \n",
       "aa       0.914183  0.201098  0.845985  ...  0.578594  0.673429  0.278861   \n",
       "abandon  0.914983  0.200809  0.846577  ...  0.578808  0.673362  0.279152   \n",
       "\n",
       "              765       766       767      Number     Gender    Lemma  \\\n",
       "Word                                                                    \n",
       "2D       0.081619  0.154076  0.553278  invariable   feminine       2D   \n",
       "3D       0.078074  0.143366  0.548315  invariable   feminine       3D   \n",
       "a        0.081689  0.139490  0.533415  invariable  masculine        a   \n",
       "aa       0.081218  0.139010  0.533594  invariable  masculine       aa   \n",
       "abandon  0.081560  0.139390  0.534123    singular  masculine  abandon   \n",
       "\n",
       "          Semantic  \n",
       "Word                \n",
       "2D           Other  \n",
       "3D           Other  \n",
       "a        Attribute  \n",
       "aa           Other  \n",
       "abandon      Other  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_with_features[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c5a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_count = 6\n",
    "\n",
    "# Feature to investigate in this notebook\n",
    "feature = 'Semantic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbca55",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1f403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3bcd0f",
   "metadata": {},
   "source": [
    "Split each model into train and test using k_fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ed271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noun_train = []\n",
    "y_noun_train = []\n",
    "\n",
    "X_noun_test = []\n",
    "y_noun_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75e3cefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>juge</th>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.556305</td>\n",
       "      <td>0.332741</td>\n",
       "      <td>0.806138</td>\n",
       "      <td>0.399868</td>\n",
       "      <td>0.295796</td>\n",
       "      <td>0.597677</td>\n",
       "      <td>0.914277</td>\n",
       "      <td>0.200987</td>\n",
       "      <td>0.846266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700008</td>\n",
       "      <td>0.512640</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.997353</td>\n",
       "      <td>0.197873</td>\n",
       "      <td>0.371594</td>\n",
       "      <td>0.577533</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.081579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>française</th>\n",
       "      <td>0.824371</td>\n",
       "      <td>0.555220</td>\n",
       "      <td>0.332107</td>\n",
       "      <td>0.799157</td>\n",
       "      <td>0.401698</td>\n",
       "      <td>0.301468</td>\n",
       "      <td>0.598216</td>\n",
       "      <td>0.918504</td>\n",
       "      <td>0.201774</td>\n",
       "      <td>0.845559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704230</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.510857</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.198841</td>\n",
       "      <td>0.376646</td>\n",
       "      <td>0.582651</td>\n",
       "      <td>0.671105</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.079869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>femme</th>\n",
       "      <td>0.826138</td>\n",
       "      <td>0.556252</td>\n",
       "      <td>0.332520</td>\n",
       "      <td>0.805565</td>\n",
       "      <td>0.399587</td>\n",
       "      <td>0.297251</td>\n",
       "      <td>0.597983</td>\n",
       "      <td>0.914046</td>\n",
       "      <td>0.201440</td>\n",
       "      <td>0.846156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701125</td>\n",
       "      <td>0.513597</td>\n",
       "      <td>0.518729</td>\n",
       "      <td>0.996630</td>\n",
       "      <td>0.198374</td>\n",
       "      <td>0.372877</td>\n",
       "      <td>0.578251</td>\n",
       "      <td>0.672666</td>\n",
       "      <td>0.278291</td>\n",
       "      <td>0.081134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citoyens</th>\n",
       "      <td>0.826304</td>\n",
       "      <td>0.555997</td>\n",
       "      <td>0.331438</td>\n",
       "      <td>0.805619</td>\n",
       "      <td>0.399750</td>\n",
       "      <td>0.297170</td>\n",
       "      <td>0.597740</td>\n",
       "      <td>0.913954</td>\n",
       "      <td>0.201278</td>\n",
       "      <td>0.845734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>0.512963</td>\n",
       "      <td>0.517433</td>\n",
       "      <td>0.996573</td>\n",
       "      <td>0.198081</td>\n",
       "      <td>0.374021</td>\n",
       "      <td>0.579020</td>\n",
       "      <td>0.673343</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.081301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professeur</th>\n",
       "      <td>0.823892</td>\n",
       "      <td>0.554782</td>\n",
       "      <td>0.330126</td>\n",
       "      <td>0.798092</td>\n",
       "      <td>0.402014</td>\n",
       "      <td>0.300715</td>\n",
       "      <td>0.599464</td>\n",
       "      <td>0.918413</td>\n",
       "      <td>0.200676</td>\n",
       "      <td>0.845716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706020</td>\n",
       "      <td>0.522638</td>\n",
       "      <td>0.510830</td>\n",
       "      <td>0.995195</td>\n",
       "      <td>0.198739</td>\n",
       "      <td>0.376953</td>\n",
       "      <td>0.583459</td>\n",
       "      <td>0.670208</td>\n",
       "      <td>0.283817</td>\n",
       "      <td>0.080593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musiciens</th>\n",
       "      <td>0.824060</td>\n",
       "      <td>0.554802</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>0.399926</td>\n",
       "      <td>0.299850</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.918802</td>\n",
       "      <td>0.201231</td>\n",
       "      <td>0.847934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706606</td>\n",
       "      <td>0.520884</td>\n",
       "      <td>0.511432</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.200161</td>\n",
       "      <td>0.376278</td>\n",
       "      <td>0.581334</td>\n",
       "      <td>0.670382</td>\n",
       "      <td>0.282138</td>\n",
       "      <td>0.082070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidat</th>\n",
       "      <td>0.824976</td>\n",
       "      <td>0.556532</td>\n",
       "      <td>0.331263</td>\n",
       "      <td>0.802573</td>\n",
       "      <td>0.400902</td>\n",
       "      <td>0.300917</td>\n",
       "      <td>0.597641</td>\n",
       "      <td>0.916143</td>\n",
       "      <td>0.203104</td>\n",
       "      <td>0.845831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703899</td>\n",
       "      <td>0.516425</td>\n",
       "      <td>0.511036</td>\n",
       "      <td>0.994916</td>\n",
       "      <td>0.198743</td>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.583206</td>\n",
       "      <td>0.671899</td>\n",
       "      <td>0.283080</td>\n",
       "      <td>0.079744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conseillers</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.556070</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.804476</td>\n",
       "      <td>0.399656</td>\n",
       "      <td>0.297760</td>\n",
       "      <td>0.597027</td>\n",
       "      <td>0.915039</td>\n",
       "      <td>0.201134</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703151</td>\n",
       "      <td>0.513882</td>\n",
       "      <td>0.515892</td>\n",
       "      <td>0.996798</td>\n",
       "      <td>0.198384</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.579279</td>\n",
       "      <td>0.672453</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.080852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>épouse</th>\n",
       "      <td>0.826211</td>\n",
       "      <td>0.556320</td>\n",
       "      <td>0.332777</td>\n",
       "      <td>0.805629</td>\n",
       "      <td>0.400047</td>\n",
       "      <td>0.296790</td>\n",
       "      <td>0.597891</td>\n",
       "      <td>0.914350</td>\n",
       "      <td>0.201516</td>\n",
       "      <td>0.846018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700312</td>\n",
       "      <td>0.513997</td>\n",
       "      <td>0.519464</td>\n",
       "      <td>0.997105</td>\n",
       "      <td>0.198126</td>\n",
       "      <td>0.372154</td>\n",
       "      <td>0.577675</td>\n",
       "      <td>0.673093</td>\n",
       "      <td>0.278377</td>\n",
       "      <td>0.081435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dirigeants</th>\n",
       "      <td>0.826117</td>\n",
       "      <td>0.556091</td>\n",
       "      <td>0.331851</td>\n",
       "      <td>0.805073</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>0.297197</td>\n",
       "      <td>0.597642</td>\n",
       "      <td>0.915347</td>\n",
       "      <td>0.201145</td>\n",
       "      <td>0.845747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701966</td>\n",
       "      <td>0.514066</td>\n",
       "      <td>0.517013</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.197763</td>\n",
       "      <td>0.374340</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.279411</td>\n",
       "      <td>0.081198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>présidente</th>\n",
       "      <td>0.825948</td>\n",
       "      <td>0.554440</td>\n",
       "      <td>0.332018</td>\n",
       "      <td>0.802690</td>\n",
       "      <td>0.400782</td>\n",
       "      <td>0.298880</td>\n",
       "      <td>0.598476</td>\n",
       "      <td>0.919785</td>\n",
       "      <td>0.198908</td>\n",
       "      <td>0.846833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704182</td>\n",
       "      <td>0.517330</td>\n",
       "      <td>0.512634</td>\n",
       "      <td>0.996077</td>\n",
       "      <td>0.197064</td>\n",
       "      <td>0.376771</td>\n",
       "      <td>0.582577</td>\n",
       "      <td>0.672288</td>\n",
       "      <td>0.282160</td>\n",
       "      <td>0.080848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>père</th>\n",
       "      <td>0.826077</td>\n",
       "      <td>0.556238</td>\n",
       "      <td>0.332658</td>\n",
       "      <td>0.805259</td>\n",
       "      <td>0.399914</td>\n",
       "      <td>0.297072</td>\n",
       "      <td>0.598119</td>\n",
       "      <td>0.914486</td>\n",
       "      <td>0.200727</td>\n",
       "      <td>0.846284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701191</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>0.518455</td>\n",
       "      <td>0.996831</td>\n",
       "      <td>0.198349</td>\n",
       "      <td>0.373107</td>\n",
       "      <td>0.578440</td>\n",
       "      <td>0.673277</td>\n",
       "      <td>0.278822</td>\n",
       "      <td>0.081362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patrons</th>\n",
       "      <td>0.826474</td>\n",
       "      <td>0.556584</td>\n",
       "      <td>0.332685</td>\n",
       "      <td>0.805596</td>\n",
       "      <td>0.400103</td>\n",
       "      <td>0.296018</td>\n",
       "      <td>0.597820</td>\n",
       "      <td>0.914768</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.846624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700140</td>\n",
       "      <td>0.513053</td>\n",
       "      <td>0.519202</td>\n",
       "      <td>0.997054</td>\n",
       "      <td>0.197755</td>\n",
       "      <td>0.372163</td>\n",
       "      <td>0.577934</td>\n",
       "      <td>0.673562</td>\n",
       "      <td>0.278984</td>\n",
       "      <td>0.081590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client</th>\n",
       "      <td>0.827105</td>\n",
       "      <td>0.552253</td>\n",
       "      <td>0.330682</td>\n",
       "      <td>0.799543</td>\n",
       "      <td>0.401037</td>\n",
       "      <td>0.298736</td>\n",
       "      <td>0.597270</td>\n",
       "      <td>0.922142</td>\n",
       "      <td>0.191482</td>\n",
       "      <td>0.846690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704706</td>\n",
       "      <td>0.517757</td>\n",
       "      <td>0.508985</td>\n",
       "      <td>0.991774</td>\n",
       "      <td>0.197491</td>\n",
       "      <td>0.377940</td>\n",
       "      <td>0.583971</td>\n",
       "      <td>0.669325</td>\n",
       "      <td>0.286516</td>\n",
       "      <td>0.077329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frères</th>\n",
       "      <td>0.825619</td>\n",
       "      <td>0.555620</td>\n",
       "      <td>0.331954</td>\n",
       "      <td>0.804746</td>\n",
       "      <td>0.400170</td>\n",
       "      <td>0.297473</td>\n",
       "      <td>0.597994</td>\n",
       "      <td>0.915290</td>\n",
       "      <td>0.201050</td>\n",
       "      <td>0.845851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702488</td>\n",
       "      <td>0.514583</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.198801</td>\n",
       "      <td>0.374378</td>\n",
       "      <td>0.579110</td>\n",
       "      <td>0.672709</td>\n",
       "      <td>0.279645</td>\n",
       "      <td>0.081155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maîtres</th>\n",
       "      <td>0.824109</td>\n",
       "      <td>0.555995</td>\n",
       "      <td>0.331680</td>\n",
       "      <td>0.800584</td>\n",
       "      <td>0.403889</td>\n",
       "      <td>0.299492</td>\n",
       "      <td>0.599974</td>\n",
       "      <td>0.913880</td>\n",
       "      <td>0.204569</td>\n",
       "      <td>0.843766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704003</td>\n",
       "      <td>0.522080</td>\n",
       "      <td>0.512090</td>\n",
       "      <td>0.995343</td>\n",
       "      <td>0.202743</td>\n",
       "      <td>0.378774</td>\n",
       "      <td>0.581502</td>\n",
       "      <td>0.669495</td>\n",
       "      <td>0.282682</td>\n",
       "      <td>0.079035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>général</th>\n",
       "      <td>0.825507</td>\n",
       "      <td>0.556549</td>\n",
       "      <td>0.331635</td>\n",
       "      <td>0.802385</td>\n",
       "      <td>0.400821</td>\n",
       "      <td>0.299075</td>\n",
       "      <td>0.597464</td>\n",
       "      <td>0.914741</td>\n",
       "      <td>0.201341</td>\n",
       "      <td>0.845454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703788</td>\n",
       "      <td>0.517633</td>\n",
       "      <td>0.513662</td>\n",
       "      <td>0.996097</td>\n",
       "      <td>0.199581</td>\n",
       "      <td>0.377435</td>\n",
       "      <td>0.582019</td>\n",
       "      <td>0.671582</td>\n",
       "      <td>0.281055</td>\n",
       "      <td>0.080158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>victime</th>\n",
       "      <td>0.825861</td>\n",
       "      <td>0.556421</td>\n",
       "      <td>0.332419</td>\n",
       "      <td>0.803155</td>\n",
       "      <td>0.399203</td>\n",
       "      <td>0.297428</td>\n",
       "      <td>0.596925</td>\n",
       "      <td>0.915164</td>\n",
       "      <td>0.200921</td>\n",
       "      <td>0.845516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703490</td>\n",
       "      <td>0.516202</td>\n",
       "      <td>0.514861</td>\n",
       "      <td>0.996475</td>\n",
       "      <td>0.198612</td>\n",
       "      <td>0.376605</td>\n",
       "      <td>0.580798</td>\n",
       "      <td>0.672285</td>\n",
       "      <td>0.280755</td>\n",
       "      <td>0.081067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docteur</th>\n",
       "      <td>0.825392</td>\n",
       "      <td>0.555833</td>\n",
       "      <td>0.332435</td>\n",
       "      <td>0.803768</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>0.297086</td>\n",
       "      <td>0.597647</td>\n",
       "      <td>0.914479</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>0.846185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703136</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.515898</td>\n",
       "      <td>0.995867</td>\n",
       "      <td>0.198741</td>\n",
       "      <td>0.374698</td>\n",
       "      <td>0.580258</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.279035</td>\n",
       "      <td>0.081325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>être</th>\n",
       "      <td>0.826256</td>\n",
       "      <td>0.555947</td>\n",
       "      <td>0.331910</td>\n",
       "      <td>0.805063</td>\n",
       "      <td>0.399154</td>\n",
       "      <td>0.297016</td>\n",
       "      <td>0.597755</td>\n",
       "      <td>0.914115</td>\n",
       "      <td>0.200972</td>\n",
       "      <td>0.846595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702426</td>\n",
       "      <td>0.514860</td>\n",
       "      <td>0.517451</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.199035</td>\n",
       "      <td>0.374228</td>\n",
       "      <td>0.579905</td>\n",
       "      <td>0.673061</td>\n",
       "      <td>0.279131</td>\n",
       "      <td>0.081583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>princes</th>\n",
       "      <td>0.825874</td>\n",
       "      <td>0.552358</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.803500</td>\n",
       "      <td>0.402375</td>\n",
       "      <td>0.298527</td>\n",
       "      <td>0.599686</td>\n",
       "      <td>0.919948</td>\n",
       "      <td>0.197344</td>\n",
       "      <td>0.844729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703143</td>\n",
       "      <td>0.516995</td>\n",
       "      <td>0.512423</td>\n",
       "      <td>0.994841</td>\n",
       "      <td>0.197658</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>0.580828</td>\n",
       "      <td>0.669974</td>\n",
       "      <td>0.282987</td>\n",
       "      <td>0.079623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambassadeur</th>\n",
       "      <td>0.825435</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0.803983</td>\n",
       "      <td>0.400720</td>\n",
       "      <td>0.298471</td>\n",
       "      <td>0.597692</td>\n",
       "      <td>0.915810</td>\n",
       "      <td>0.202349</td>\n",
       "      <td>0.845497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702248</td>\n",
       "      <td>0.515798</td>\n",
       "      <td>0.515687</td>\n",
       "      <td>0.996615</td>\n",
       "      <td>0.198145</td>\n",
       "      <td>0.375554</td>\n",
       "      <td>0.580679</td>\n",
       "      <td>0.672751</td>\n",
       "      <td>0.280438</td>\n",
       "      <td>0.080750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maître</th>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.555357</td>\n",
       "      <td>0.331385</td>\n",
       "      <td>0.800223</td>\n",
       "      <td>0.404969</td>\n",
       "      <td>0.299918</td>\n",
       "      <td>0.596882</td>\n",
       "      <td>0.917467</td>\n",
       "      <td>0.198622</td>\n",
       "      <td>0.846197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704876</td>\n",
       "      <td>0.523521</td>\n",
       "      <td>0.511533</td>\n",
       "      <td>0.994885</td>\n",
       "      <td>0.201175</td>\n",
       "      <td>0.377146</td>\n",
       "      <td>0.581726</td>\n",
       "      <td>0.669362</td>\n",
       "      <td>0.284546</td>\n",
       "      <td>0.079728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ami</th>\n",
       "      <td>0.825734</td>\n",
       "      <td>0.555589</td>\n",
       "      <td>0.332161</td>\n",
       "      <td>0.803397</td>\n",
       "      <td>0.399455</td>\n",
       "      <td>0.296761</td>\n",
       "      <td>0.598217</td>\n",
       "      <td>0.915111</td>\n",
       "      <td>0.200353</td>\n",
       "      <td>0.846337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703393</td>\n",
       "      <td>0.515085</td>\n",
       "      <td>0.515290</td>\n",
       "      <td>0.996127</td>\n",
       "      <td>0.198447</td>\n",
       "      <td>0.376045</td>\n",
       "      <td>0.581548</td>\n",
       "      <td>0.672137</td>\n",
       "      <td>0.280483</td>\n",
       "      <td>0.080643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>médecin</th>\n",
       "      <td>0.824334</td>\n",
       "      <td>0.555832</td>\n",
       "      <td>0.332796</td>\n",
       "      <td>0.799260</td>\n",
       "      <td>0.401110</td>\n",
       "      <td>0.297403</td>\n",
       "      <td>0.598756</td>\n",
       "      <td>0.915509</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.846672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705992</td>\n",
       "      <td>0.518821</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>0.994552</td>\n",
       "      <td>0.200238</td>\n",
       "      <td>0.378976</td>\n",
       "      <td>0.583172</td>\n",
       "      <td>0.669414</td>\n",
       "      <td>0.281026</td>\n",
       "      <td>0.079807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veuve</th>\n",
       "      <td>0.825568</td>\n",
       "      <td>0.555585</td>\n",
       "      <td>0.332450</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.400733</td>\n",
       "      <td>0.299973</td>\n",
       "      <td>0.598903</td>\n",
       "      <td>0.918104</td>\n",
       "      <td>0.199802</td>\n",
       "      <td>0.845908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.518762</td>\n",
       "      <td>0.514461</td>\n",
       "      <td>0.996577</td>\n",
       "      <td>0.197667</td>\n",
       "      <td>0.374237</td>\n",
       "      <td>0.580046</td>\n",
       "      <td>0.672618</td>\n",
       "      <td>0.282079</td>\n",
       "      <td>0.081216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officier</th>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.552754</td>\n",
       "      <td>0.328915</td>\n",
       "      <td>0.798604</td>\n",
       "      <td>0.401467</td>\n",
       "      <td>0.298352</td>\n",
       "      <td>0.598362</td>\n",
       "      <td>0.919485</td>\n",
       "      <td>0.202252</td>\n",
       "      <td>0.847575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704137</td>\n",
       "      <td>0.521521</td>\n",
       "      <td>0.509496</td>\n",
       "      <td>0.994062</td>\n",
       "      <td>0.201151</td>\n",
       "      <td>0.378755</td>\n",
       "      <td>0.582586</td>\n",
       "      <td>0.670385</td>\n",
       "      <td>0.284183</td>\n",
       "      <td>0.081371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neveu</th>\n",
       "      <td>0.825324</td>\n",
       "      <td>0.556239</td>\n",
       "      <td>0.332195</td>\n",
       "      <td>0.803151</td>\n",
       "      <td>0.400674</td>\n",
       "      <td>0.298946</td>\n",
       "      <td>0.598697</td>\n",
       "      <td>0.915947</td>\n",
       "      <td>0.200680</td>\n",
       "      <td>0.845864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702178</td>\n",
       "      <td>0.516353</td>\n",
       "      <td>0.515438</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>0.198499</td>\n",
       "      <td>0.375028</td>\n",
       "      <td>0.580254</td>\n",
       "      <td>0.672775</td>\n",
       "      <td>0.280228</td>\n",
       "      <td>0.081096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5    \\\n",
       "Word                                                                      \n",
       "juge         0.826999  0.556305  0.332741  0.806138  0.399868  0.295796   \n",
       "française    0.824371  0.555220  0.332107  0.799157  0.401698  0.301468   \n",
       "femme        0.826138  0.556252  0.332520  0.805565  0.399587  0.297251   \n",
       "citoyens     0.826304  0.555997  0.331438  0.805619  0.399750  0.297170   \n",
       "professeur   0.823892  0.554782  0.330126  0.798092  0.402014  0.300715   \n",
       "musiciens    0.824060  0.554802  0.330870  0.801526  0.399926  0.299850   \n",
       "candidat     0.824976  0.556532  0.331263  0.802573  0.400902  0.300917   \n",
       "conseillers  0.825939  0.556070  0.331554  0.804476  0.399656  0.297760   \n",
       "épouse       0.826211  0.556320  0.332777  0.805629  0.400047  0.296790   \n",
       "dirigeants   0.826117  0.556091  0.331851  0.805073  0.399795  0.297197   \n",
       "présidente   0.825948  0.554440  0.332018  0.802690  0.400782  0.298880   \n",
       "père         0.826077  0.556238  0.332658  0.805259  0.399914  0.297072   \n",
       "patrons      0.826474  0.556584  0.332685  0.805596  0.400103  0.296018   \n",
       "client       0.827105  0.552253  0.330682  0.799543  0.401037  0.298736   \n",
       "frères       0.825619  0.555620  0.331954  0.804746  0.400170  0.297473   \n",
       "maîtres      0.824109  0.555995  0.331680  0.800584  0.403889  0.299492   \n",
       "général      0.825507  0.556549  0.331635  0.802385  0.400821  0.299075   \n",
       "victime      0.825861  0.556421  0.332419  0.803155  0.399203  0.297428   \n",
       "docteur      0.825392  0.555833  0.332435  0.803768  0.399413  0.297086   \n",
       "être         0.826256  0.555947  0.331910  0.805063  0.399154  0.297016   \n",
       "princes      0.825874  0.552358  0.332700  0.803500  0.402375  0.298527   \n",
       "ambassadeur  0.825435  0.556263  0.331126  0.803983  0.400720  0.298471   \n",
       "maître       0.824675  0.555357  0.331385  0.800223  0.404969  0.299918   \n",
       "ami          0.825734  0.555589  0.332161  0.803397  0.399455  0.296761   \n",
       "médecin      0.824334  0.555832  0.332796  0.799260  0.401110  0.297403   \n",
       "veuve        0.825568  0.555585  0.332450  0.801942  0.400733  0.299973   \n",
       "officier     0.823002  0.552754  0.328915  0.798604  0.401467  0.298352   \n",
       "neveu        0.825324  0.556239  0.332195  0.803151  0.400674  0.298946   \n",
       "\n",
       "                  6         7         8         9    ...       756       757  \\\n",
       "Word                                                 ...                       \n",
       "juge         0.597677  0.914277  0.200987  0.846266  ...  0.700008  0.512640   \n",
       "française    0.598216  0.918504  0.201774  0.845559  ...  0.704230  0.520594   \n",
       "femme        0.597983  0.914046  0.201440  0.846156  ...  0.701125  0.513597   \n",
       "citoyens     0.597740  0.913954  0.201278  0.845734  ...  0.701905  0.512963   \n",
       "professeur   0.599464  0.918413  0.200676  0.845716  ...  0.706020  0.522638   \n",
       "musiciens    0.597505  0.918802  0.201231  0.847934  ...  0.706606  0.520884   \n",
       "candidat     0.597641  0.916143  0.203104  0.845831  ...  0.703899  0.516425   \n",
       "conseillers  0.597027  0.915039  0.201134  0.845616  ...  0.703151  0.513882   \n",
       "épouse       0.597891  0.914350  0.201516  0.846018  ...  0.700312  0.513997   \n",
       "dirigeants   0.597642  0.915347  0.201145  0.845747  ...  0.701966  0.514066   \n",
       "présidente   0.598476  0.919785  0.198908  0.846833  ...  0.704182  0.517330   \n",
       "père         0.598119  0.914486  0.200727  0.846284  ...  0.701191  0.513520   \n",
       "patrons      0.597820  0.914768  0.201311  0.846624  ...  0.700140  0.513053   \n",
       "client       0.597270  0.922142  0.191482  0.846690  ...  0.704706  0.517757   \n",
       "frères       0.597994  0.915290  0.201050  0.845851  ...  0.702488  0.514583   \n",
       "maîtres      0.599974  0.913880  0.204569  0.843766  ...  0.704003  0.522080   \n",
       "général      0.597464  0.914741  0.201341  0.845454  ...  0.703788  0.517633   \n",
       "victime      0.596925  0.915164  0.200921  0.845516  ...  0.703490  0.516202   \n",
       "docteur      0.597647  0.914479  0.200436  0.846185  ...  0.703136  0.515495   \n",
       "être         0.597755  0.914115  0.200972  0.846595  ...  0.702426  0.514860   \n",
       "princes      0.599686  0.919948  0.197344  0.844729  ...  0.703143  0.516995   \n",
       "ambassadeur  0.597692  0.915810  0.202349  0.845497  ...  0.702248  0.515798   \n",
       "maître       0.596882  0.917467  0.198622  0.846197  ...  0.704876  0.523521   \n",
       "ami          0.598217  0.915111  0.200353  0.846337  ...  0.703393  0.515085   \n",
       "médecin      0.598756  0.915509  0.201800  0.846672  ...  0.705992  0.518821   \n",
       "veuve        0.598903  0.918104  0.199802  0.845908  ...  0.702599  0.518762   \n",
       "officier     0.598362  0.919485  0.202252  0.847575  ...  0.704137  0.521521   \n",
       "neveu        0.598697  0.915947  0.200680  0.845864  ...  0.702178  0.516353   \n",
       "\n",
       "                  758       759       760       761       762       763  \\\n",
       "Word                                                                      \n",
       "juge         0.519824  0.997353  0.197873  0.371594  0.577533  0.673251   \n",
       "française    0.510857  0.995831  0.198841  0.376646  0.582651  0.671105   \n",
       "femme        0.518729  0.996630  0.198374  0.372877  0.578251  0.672666   \n",
       "citoyens     0.517433  0.996573  0.198081  0.374021  0.579020  0.673343   \n",
       "professeur   0.510830  0.995195  0.198739  0.376953  0.583459  0.670208   \n",
       "musiciens    0.511432  0.997359  0.200161  0.376278  0.581334  0.670382   \n",
       "candidat     0.511036  0.994916  0.198743  0.376588  0.583206  0.671899   \n",
       "conseillers  0.515892  0.996798  0.198384  0.376200  0.579279  0.672453   \n",
       "épouse       0.519464  0.997105  0.198126  0.372154  0.577675  0.673093   \n",
       "dirigeants   0.517013  0.996794  0.197763  0.374340  0.579167  0.673235   \n",
       "présidente   0.512634  0.996077  0.197064  0.376771  0.582577  0.672288   \n",
       "père         0.518455  0.996831  0.198349  0.373107  0.578440  0.673277   \n",
       "patrons      0.519202  0.997054  0.197755  0.372163  0.577934  0.673562   \n",
       "client       0.508985  0.991774  0.197491  0.377940  0.583971  0.669325   \n",
       "frères       0.516373  0.996825  0.198801  0.374378  0.579110  0.672709   \n",
       "maîtres      0.512090  0.995343  0.202743  0.378774  0.581502  0.669495   \n",
       "général      0.513662  0.996097  0.199581  0.377435  0.582019  0.671582   \n",
       "victime      0.514861  0.996475  0.198612  0.376605  0.580798  0.672285   \n",
       "docteur      0.515898  0.995867  0.198741  0.374698  0.580258  0.671946   \n",
       "être         0.517451  0.996503  0.199035  0.374228  0.579905  0.673061   \n",
       "princes      0.512423  0.994841  0.197658  0.375595  0.580828  0.669974   \n",
       "ambassadeur  0.515687  0.996615  0.198145  0.375554  0.580679  0.672751   \n",
       "maître       0.511533  0.994885  0.201175  0.377146  0.581726  0.669362   \n",
       "ami          0.515290  0.996127  0.198447  0.376045  0.581548  0.672137   \n",
       "médecin      0.510938  0.994552  0.200238  0.378976  0.583172  0.669414   \n",
       "veuve        0.514461  0.996577  0.197667  0.374237  0.580046  0.672618   \n",
       "officier     0.509496  0.994062  0.201151  0.378755  0.582586  0.670385   \n",
       "neveu        0.515438  0.996670  0.198499  0.375028  0.580254  0.672775   \n",
       "\n",
       "                  764       765  \n",
       "Word                             \n",
       "juge         0.278180  0.081579  \n",
       "française    0.284217  0.079869  \n",
       "femme        0.278291  0.081134  \n",
       "citoyens     0.279074  0.081301  \n",
       "professeur   0.283817  0.080593  \n",
       "musiciens    0.282138  0.082070  \n",
       "candidat     0.283080  0.079744  \n",
       "conseillers  0.280372  0.080852  \n",
       "épouse       0.278377  0.081435  \n",
       "dirigeants   0.279411  0.081198  \n",
       "présidente   0.282160  0.080848  \n",
       "père         0.278822  0.081362  \n",
       "patrons      0.278984  0.081590  \n",
       "client       0.286516  0.077329  \n",
       "frères       0.279645  0.081155  \n",
       "maîtres      0.282682  0.079035  \n",
       "général      0.281055  0.080158  \n",
       "victime      0.280755  0.081067  \n",
       "docteur      0.279035  0.081325  \n",
       "être         0.279131  0.081583  \n",
       "princes      0.282987  0.079623  \n",
       "ambassadeur  0.280438  0.080750  \n",
       "maître       0.284546  0.079728  \n",
       "ami          0.280483  0.080643  \n",
       "médecin      0.281026  0.079807  \n",
       "veuve        0.282079  0.081216  \n",
       "officier     0.284183  0.081371  \n",
       "neveu        0.280228  0.081096  \n",
       "\n",
       "[28 rows x 766 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_noun_test[-1][0][y_noun_test[-1][0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30d81e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ce6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    X, y = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.Number != 'invariable')],\n",
    "                                           feature_col_count=feature_col_count,\n",
    "                                           feature_name=feature,\n",
    "                                           normalize=False,\n",
    "                                           encode=True,\n",
    "                                           encode_as1='Person',\n",
    "                                           split=False,\n",
    "                                           balance=True)\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    \n",
    "    X_tests = []\n",
    "    y_tests = []\n",
    "    \n",
    "    X_folds = np.array_split(X, n_folds)\n",
    "    y_folds = np.array_split(y, n_folds)\n",
    "    \n",
    "    for i in range(n_folds):\n",
    "        X_trains.append(pd.DataFrame(np.concatenate(X_folds[:i] + X_folds[i+1:])))\n",
    "        y_trains.append(np.concatenate(y_folds[:i] + y_folds[i+1:]))\n",
    "\n",
    "        X_folds[i].columns = X_folds[i].columns.map(int)\n",
    "        X_tests.append(X_folds[i])\n",
    "        y_tests.append(y_folds[i])\n",
    "        \n",
    "    \n",
    "    X_noun_train.append(X_trains)\n",
    "    X_noun_test.append(X_tests)\n",
    "    \n",
    "    y_noun_train.append(y_trains)\n",
    "    y_noun_test.append(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4593703a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 fold size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flau_small_c</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_u</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_c</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_large_c</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cam_base</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_large</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_base</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_u</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_base</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_c</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1 fold size\n",
       "flau_small_c             120\n",
       "flau_base_u              124\n",
       "flau_base_c              120\n",
       "flau_large_c             120\n",
       "cam_base                  97\n",
       "xlm_large                 26\n",
       "xlm_base                  26\n",
       "bert_base_u               56\n",
       "distilbert_base           50\n",
       "bert_base_c               50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes = pd.DataFrame(index=labels)\n",
    "dataset_sizes['1 fold size'] = [len(x[0]) for x in X_noun_test]\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8906983",
   "metadata": {},
   "source": [
    "## Non-independent dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e55053",
   "metadata": {},
   "source": [
    "Calculate non-independendent dimensions for each of _k_ splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6744ee",
   "metadata": {},
   "source": [
    "ANOVA test with p-value < 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b8b925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ae509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    anova_dims.append([])\n",
    "    for j in range(n_folds):\n",
    "        anova_dims[i].append(get_anova_dims(X_noun_train[i][j], y_noun_train[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc2848",
   "metadata": {},
   "source": [
    "Get dimensions where MI > 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19cf81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5b9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mi_dims.append([])\n",
    "    for j in range(n_folds):\n",
    "        mi_dims[i].append(get_mi_dims(X_noun_train[i][j], y_noun_train[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e073ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    for j in range(n_folds):\n",
    "        temp = list(map(lambda x: int(x), mi_dims[i][j]))\n",
    "        mi_dims[i][j] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadfa061",
   "metadata": {},
   "source": [
    "Get dimensions that are both found by the ANOVA independency test and MI test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40f7c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ind_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb3fe5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    non_ind_dims.append([])\n",
    "    for j in range(n_folds):\n",
    "        non_ind_dims[i].append(list(set(anova_dims[i][j]).intersection(mi_dims[i][j])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de917ea7",
   "metadata": {},
   "source": [
    "Stats about the number of dimensions for each model for the 1st split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5acb0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ind_df = pd.DataFrame(index=labels, columns=['ANOVA', 'MI', 'Total non independent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ceb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ind_df['ANOVA'] = [len(x[0]) for x in anova_dims]\n",
    "non_ind_df['MI'] = [len(x[0]) for x in mi_dims]\n",
    "non_ind_df['Total non independent'] = [len(x[0]) for x in non_ind_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b092b91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANOVA</th>\n",
       "      <th>MI</th>\n",
       "      <th>Total non independent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flau_small_c</th>\n",
       "      <td>208</td>\n",
       "      <td>346</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_u</th>\n",
       "      <td>68</td>\n",
       "      <td>421</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_c</th>\n",
       "      <td>265</td>\n",
       "      <td>491</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_large_c</th>\n",
       "      <td>396</td>\n",
       "      <td>649</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cam_base</th>\n",
       "      <td>12</td>\n",
       "      <td>459</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_large</th>\n",
       "      <td>4</td>\n",
       "      <td>443</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_base</th>\n",
       "      <td>1</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_u</th>\n",
       "      <td>3</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_base</th>\n",
       "      <td>54</td>\n",
       "      <td>413</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_c</th>\n",
       "      <td>57</td>\n",
       "      <td>442</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ANOVA   MI  Total non independent\n",
       "flau_small_c       208  346                    173\n",
       "flau_base_u         68  421                     51\n",
       "flau_base_c        265  491                    207\n",
       "flau_large_c       396  649                    312\n",
       "cam_base            12  459                     10\n",
       "xlm_large            4  443                      2\n",
       "xlm_base             1  451                      1\n",
       "bert_base_u          3  374                      2\n",
       "distilbert_base     54  413                     36\n",
       "bert_base_c         57  442                     47"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3810a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbb187d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    dims[labels[i]] = {}\n",
    "    dims[labels[i]]['All dims'] = [X_noun_train[i][0].columns]*n_folds\n",
    "    dims[labels[i]]['ANOVA'] = anova_dims[i]\n",
    "    dims[labels[i]]['MI'] = mi_dims[i]\n",
    "    dims[labels[i]]['All non ind'] = non_ind_dims[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c003eed",
   "metadata": {},
   "source": [
    "## Important dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a1730",
   "metadata": {},
   "source": [
    "We can test different $\\alpha$ values: 1%, 5%, 10%, 25%, 50%, 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6ad2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1, 5, 10, 25, 50, 75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158f05b",
   "metadata": {},
   "source": [
    "Train Logistic Regression on train set for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50b323ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87159744",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    lr_res.append([])\n",
    "    for j in range(n_folds):\n",
    "        lr_res[i].append(lr(X_noun_train[i][j], y_noun_train[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913390c",
   "metadata": {},
   "source": [
    "Train Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f1c63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ed42a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    perceptron_res.append([])\n",
    "    for j in range(n_folds):\n",
    "        perceptron_res[i].append(perceptron(X_noun_train[i][j], y_noun_train[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01bfbb",
   "metadata": {},
   "source": [
    "Compute correlation to the gender vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc3e5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b184213",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    corr_res.append([])\n",
    "    for j in range(n_folds):\n",
    "        corr_res[i].append(correlation(X_noun_train[i][j], y_noun_train[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0a472fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    for alpha in alphas:\n",
    "        dims[labels[i]][f'LR{alpha}'] = []\n",
    "        dims[labels[i]][f'Perc{alpha}'] = []\n",
    "        dims[labels[i]][f'Corr{alpha}'] = []\n",
    "        dims[labels[i]][f'All imp dims{alpha}'] = []\n",
    "        for j in range(n_folds):\n",
    "            num_imp_dims = len(X_noun_test[i][0].columns)*alpha//100\n",
    "            lr_dims = [x[0] for x in lr_res[i][j][:num_imp_dims]]\n",
    "            perc_dims = [x[0] for x in perceptron_res[i][j][:num_imp_dims]]\n",
    "            corr_dims = [x[0] for x in corr_res[i][j][:num_imp_dims]]\n",
    "            dims[labels[i]][f'LR{alpha}'].append(lr_dims)\n",
    "            dims[labels[i]][f'Perc{alpha}'].append(perc_dims)\n",
    "            dims[labels[i]][f'Corr{alpha}'].append(corr_dims)\n",
    "            dims[labels[i]][f'All imp dims{alpha}'].append(list(set(lr_dims).intersection(perc_dims).intersection(corr_dims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d07b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[121, 417, 0, 24, 358],\n",
       " [121, 295, 276, 70, 495],\n",
       " [121, 495, 295, 146, 375],\n",
       " [121, 295, 276, 495, 417],\n",
       " [121, 295, 375, 417, 364]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims[labels[0]]['LR1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9684dd",
   "metadata": {},
   "source": [
    "## Compute medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3a6f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0425348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians[labels[i]] = {}\n",
    "    for dim_group in dims[labels[i]].keys():\n",
    "        medians[labels[i]][dim_group] = []\n",
    "        n = len(dims[labels[i]][dim_group])\n",
    "        for j in range(n_folds):\n",
    "            dim_list = dims[labels[i]][dim_group][j] if n == n_folds else list(dims[labels[i]][dim_group])\n",
    "            # Median of dimensions where feature vector is equal to 0\n",
    "            median_0 = X_noun_train[i][j][y_noun_train[i][j] == 0][dim_list].median()\n",
    "            # Median of dimensions where feature vector is equal to 1\n",
    "            median_1 = X_noun_train[i][j][y_noun_train[i][j] == 1][dim_list].median()\n",
    "\n",
    "            medians[labels[i]][dim_group].append({\n",
    "                    '0': median_0,\n",
    "                    '1': median_1\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7717e",
   "metadata": {},
   "source": [
    "We can compare the number of dimensions found by each test for each model in the first fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8875ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_lens = {}\n",
    "\n",
    "for model in dims.keys():\n",
    "    dim_lens[model] = {}\n",
    "    for dim_group in dims[model].keys():\n",
    "        dim_lens[model][dim_group] = len(dims[model][dim_group][0]) if dim_group != 'All dims' else \\\n",
    "                len(dims[model][dim_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5a5791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flau_small_c</th>\n",
       "      <th>flau_base_u</th>\n",
       "      <th>flau_base_c</th>\n",
       "      <th>flau_large_c</th>\n",
       "      <th>cam_base</th>\n",
       "      <th>xlm_large</th>\n",
       "      <th>xlm_base</th>\n",
       "      <th>bert_base_u</th>\n",
       "      <th>distilbert_base</th>\n",
       "      <th>bert_base_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All dims</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANOVA</th>\n",
       "      <td>208</td>\n",
       "      <td>68</td>\n",
       "      <td>265</td>\n",
       "      <td>396</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>346</td>\n",
       "      <td>421</td>\n",
       "      <td>491</td>\n",
       "      <td>649</td>\n",
       "      <td>459</td>\n",
       "      <td>443</td>\n",
       "      <td>451</td>\n",
       "      <td>374</td>\n",
       "      <td>413</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All non ind</th>\n",
       "      <td>173</td>\n",
       "      <td>51</td>\n",
       "      <td>207</td>\n",
       "      <td>312</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR5</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc5</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr5</th>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR10</th>\n",
       "      <td>51</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc10</th>\n",
       "      <td>51</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr10</th>\n",
       "      <td>51</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims10</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR25</th>\n",
       "      <td>127</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc25</th>\n",
       "      <td>127</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr25</th>\n",
       "      <td>127</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims25</th>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>72</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR50</th>\n",
       "      <td>255</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc50</th>\n",
       "      <td>255</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr50</th>\n",
       "      <td>255</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>511</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims50</th>\n",
       "      <td>111</td>\n",
       "      <td>135</td>\n",
       "      <td>117</td>\n",
       "      <td>226</td>\n",
       "      <td>125</td>\n",
       "      <td>165</td>\n",
       "      <td>94</td>\n",
       "      <td>113</td>\n",
       "      <td>102</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR75</th>\n",
       "      <td>382</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc75</th>\n",
       "      <td>382</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr75</th>\n",
       "      <td>382</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>766</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims75</th>\n",
       "      <td>233</td>\n",
       "      <td>341</td>\n",
       "      <td>321</td>\n",
       "      <td>471</td>\n",
       "      <td>329</td>\n",
       "      <td>447</td>\n",
       "      <td>304</td>\n",
       "      <td>321</td>\n",
       "      <td>325</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                flau_small_c  flau_base_u  flau_base_c  flau_large_c  \\\n",
       "All dims                   5            5            5             5   \n",
       "ANOVA                    208           68          265           396   \n",
       "MI                       346          421          491           649   \n",
       "All non ind              173           51          207           312   \n",
       "LR1                        5            7            7            10   \n",
       "Perc1                      5            7            7            10   \n",
       "Corr1                      5            7            7            10   \n",
       "All imp dims1              1            0            0             0   \n",
       "LR5                       25           38           38            51   \n",
       "Perc5                     25           38           38            51   \n",
       "Corr5                     25           38           38            51   \n",
       "All imp dims5              3            4            4             6   \n",
       "LR10                      51           76           76           102   \n",
       "Perc10                    51           76           76           102   \n",
       "Corr10                    51           76           76           102   \n",
       "All imp dims10            13           14            9            17   \n",
       "LR25                     127          191          191           255   \n",
       "Perc25                   127          191          191           255   \n",
       "Corr25                   127          191          191           255   \n",
       "All imp dims25            44           49           31            72   \n",
       "LR50                     255          383          383           511   \n",
       "Perc50                   255          383          383           511   \n",
       "Corr50                   255          383          383           511   \n",
       "All imp dims50           111          135          117           226   \n",
       "LR75                     382          574          574           766   \n",
       "Perc75                   382          574          574           766   \n",
       "Corr75                   382          574          574           766   \n",
       "All imp dims75           233          341          321           471   \n",
       "\n",
       "                cam_base  xlm_large  xlm_base  bert_base_u  distilbert_base  \\\n",
       "All dims               5          5         5            5                5   \n",
       "ANOVA                 12          4         1            3               54   \n",
       "MI                   459        443       451          374              413   \n",
       "All non ind           10          2         1            2               36   \n",
       "LR1                    7         10         7            7                7   \n",
       "Perc1                  7         10         7            7                7   \n",
       "Corr1                  7         10         7            7                7   \n",
       "All imp dims1          0          2         1            0                1   \n",
       "LR5                   38         51        38           38               38   \n",
       "Perc5                 38         51        38           38               38   \n",
       "Corr5                 38         51        38           38               38   \n",
       "All imp dims5          3          6         4            3                2   \n",
       "LR10                  76        102        76           76               76   \n",
       "Perc10                76        102        76           76               76   \n",
       "Corr10                76        102        76           76               76   \n",
       "All imp dims10         7         15         4            8                4   \n",
       "LR25                 191        255       191          191              191   \n",
       "Perc25               191        255       191          191              191   \n",
       "Corr25               191        255       191          191              191   \n",
       "All imp dims25        34         48        24           30               27   \n",
       "LR50                 383        511       383          383              383   \n",
       "Perc50               383        511       383          383              383   \n",
       "Corr50               383        511       383          383              383   \n",
       "All imp dims50       125        165        94          113              102   \n",
       "LR75                 574        766       574          574              574   \n",
       "Perc75               574        766       574          574              574   \n",
       "Corr75               574        766       574          574              574   \n",
       "All imp dims75       329        447       304          321              325   \n",
       "\n",
       "                bert_base_c  \n",
       "All dims                  5  \n",
       "ANOVA                    57  \n",
       "MI                      442  \n",
       "All non ind              47  \n",
       "LR1                       7  \n",
       "Perc1                     7  \n",
       "Corr1                     7  \n",
       "All imp dims1             0  \n",
       "LR5                      38  \n",
       "Perc5                    38  \n",
       "Corr5                    38  \n",
       "All imp dims5             0  \n",
       "LR10                     76  \n",
       "Perc10                   76  \n",
       "Corr10                   76  \n",
       "All imp dims10            5  \n",
       "LR25                    191  \n",
       "Perc25                  191  \n",
       "Corr25                  191  \n",
       "All imp dims25           37  \n",
       "LR50                    383  \n",
       "Perc50                  383  \n",
       "Corr50                  383  \n",
       "All imp dims50          157  \n",
       "LR75                    574  \n",
       "Perc75                  574  \n",
       "Corr75                  574  \n",
       "All imp dims75          378  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dim_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e69ad",
   "metadata": {},
   "source": [
    "## Compute predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65aa14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e2426b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    y_preds[labels[i]] = {}\n",
    "    for dim_group in dims[labels[i]].keys():\n",
    "        y_preds[labels[i]][dim_group] = []\n",
    "        n = len(dims[labels[i]][dim_group])\n",
    "        for j in range(n_folds):\n",
    "            dim_list = dims[labels[i]][dim_group][j] if n == n_folds else dims[labels[i]][dim_group]\n",
    "            \n",
    "            # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "            mae0 = X_noun_test[i][j][dim_list].apply(lambda x: mean_absolute_error(medians[labels[i]][dim_group][j]['0'], x), axis=1)\n",
    "            mae1 = X_noun_test[i][j][dim_list].apply(lambda x: mean_absolute_error(medians[labels[i]][dim_group][j]['1'], x), axis=1)\n",
    "            \n",
    "            y_preds[labels[i]][dim_group].append((mae0 > mae1).apply(int))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe460e37",
   "metadata": {},
   "source": [
    "## Compute accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ced4cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c8c7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    accs[labels[i]] = {}\n",
    "    for dim_group in dims[labels[i]].keys():\n",
    "        accs[labels[i]][dim_group] = []\n",
    "        for j in range(n_folds):\n",
    "            y_true = y_noun_test[i][j]\n",
    "            y_pred = y_preds[labels[i]][dim_group][j]\n",
    "            if any(y_pred):\n",
    "                acc = accuracy_score(y_true, y_pred)\n",
    "            else:\n",
    "                acc = 0\n",
    "            accs[labels[i]][dim_group].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cde82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bedda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average accuracy between 5 folds\n",
    "avg_accs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcbc6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    avg_accs[labels[i]] = {}\n",
    "    for dim_group in dims[labels[i]].keys():\n",
    "        avg_accs[labels[i]][dim_group] = np.average(accs[labels[i]][dim_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "108f2eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flau_small_c</th>\n",
       "      <th>flau_base_u</th>\n",
       "      <th>flau_base_c</th>\n",
       "      <th>flau_large_c</th>\n",
       "      <th>cam_base</th>\n",
       "      <th>xlm_large</th>\n",
       "      <th>xlm_base</th>\n",
       "      <th>bert_base_u</th>\n",
       "      <th>distilbert_base</th>\n",
       "      <th>bert_base_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All dims</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.607094</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.399385</td>\n",
       "      <td>0.586769</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.556980</td>\n",
       "      <td>0.553143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANOVA</th>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.629871</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.531186</td>\n",
       "      <td>0.413846</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.485390</td>\n",
       "      <td>0.589388</td>\n",
       "      <td>0.638367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.634710</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.406462</td>\n",
       "      <td>0.579077</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.552735</td>\n",
       "      <td>0.557224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All non ind</th>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.629832</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.526997</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.456688</td>\n",
       "      <td>0.564980</td>\n",
       "      <td>0.638367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR1</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.573092</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.502384</td>\n",
       "      <td>0.499692</td>\n",
       "      <td>0.594769</td>\n",
       "      <td>0.449026</td>\n",
       "      <td>0.646122</td>\n",
       "      <td>0.540653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc1</th>\n",
       "      <td>0.681667</td>\n",
       "      <td>0.571309</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.558162</td>\n",
       "      <td>0.476615</td>\n",
       "      <td>0.570769</td>\n",
       "      <td>0.409675</td>\n",
       "      <td>0.577633</td>\n",
       "      <td>0.536653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr1</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.611972</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.512479</td>\n",
       "      <td>0.437846</td>\n",
       "      <td>0.563385</td>\n",
       "      <td>0.449156</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.626122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims1</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.437398</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR5</th>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.610372</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.529081</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>0.540308</td>\n",
       "      <td>0.416818</td>\n",
       "      <td>0.621388</td>\n",
       "      <td>0.540980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc5</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.615224</td>\n",
       "      <td>0.628333</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.547680</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.563385</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.593959</td>\n",
       "      <td>0.536735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr5</th>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.631537</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.539497</td>\n",
       "      <td>0.437846</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.409675</td>\n",
       "      <td>0.593306</td>\n",
       "      <td>0.634367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims5</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.560084</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>0.506271</td>\n",
       "      <td>0.453538</td>\n",
       "      <td>0.586462</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>0.426286</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR10</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.634710</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.543578</td>\n",
       "      <td>0.445846</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.633878</td>\n",
       "      <td>0.524653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc10</th>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.615198</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.537371</td>\n",
       "      <td>0.445538</td>\n",
       "      <td>0.571385</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.569388</td>\n",
       "      <td>0.565306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr10</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.623367</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.539454</td>\n",
       "      <td>0.429538</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.409610</td>\n",
       "      <td>0.597633</td>\n",
       "      <td>0.630449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims10</th>\n",
       "      <td>0.788333</td>\n",
       "      <td>0.598951</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>0.778333</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.461231</td>\n",
       "      <td>0.594154</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.581143</td>\n",
       "      <td>0.557224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR25</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.623354</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.430154</td>\n",
       "      <td>0.571077</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.617551</td>\n",
       "      <td>0.524653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc25</th>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.611946</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.541516</td>\n",
       "      <td>0.430462</td>\n",
       "      <td>0.579077</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.557061</td>\n",
       "      <td>0.549061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr25</th>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.623328</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.406154</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.597633</td>\n",
       "      <td>0.593959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims25</th>\n",
       "      <td>0.821667</td>\n",
       "      <td>0.608760</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.547745</td>\n",
       "      <td>0.445231</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.597796</td>\n",
       "      <td>0.573469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR50</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.631419</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.422462</td>\n",
       "      <td>0.579077</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.553143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc50</th>\n",
       "      <td>0.831667</td>\n",
       "      <td>0.587634</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.383692</td>\n",
       "      <td>0.586769</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.553143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr50</th>\n",
       "      <td>0.836667</td>\n",
       "      <td>0.623289</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.391077</td>\n",
       "      <td>0.563692</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.577306</td>\n",
       "      <td>0.565388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims50</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600603</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.537371</td>\n",
       "      <td>0.437846</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.593796</td>\n",
       "      <td>0.557224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR75</th>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.623289</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.586769</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.589469</td>\n",
       "      <td>0.557224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc75</th>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.605507</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.399692</td>\n",
       "      <td>0.579077</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.544816</td>\n",
       "      <td>0.561306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr75</th>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.610320</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.414462</td>\n",
       "      <td>0.571385</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.569224</td>\n",
       "      <td>0.561306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims75</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.629832</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.535309</td>\n",
       "      <td>0.399385</td>\n",
       "      <td>0.571385</td>\n",
       "      <td>0.416883</td>\n",
       "      <td>0.561143</td>\n",
       "      <td>0.565388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                flau_small_c  flau_base_u  flau_base_c  flau_large_c  \\\n",
       "All dims            0.845000     0.607094     0.593333      0.850000   \n",
       "ANOVA               0.836667     0.629871     0.601667      0.843333   \n",
       "MI                  0.840000     0.634710     0.595000      0.851667   \n",
       "All non ind         0.838333     0.629832     0.596667      0.845000   \n",
       "LR1                 0.708333     0.573092     0.573333      0.690000   \n",
       "Perc1               0.681667     0.571309     0.603333      0.723333   \n",
       "Corr1               0.733333     0.611972     0.611667      0.758333   \n",
       "All imp dims1       0.130000     0.437398     0.230000      0.130000   \n",
       "LR5                 0.803333     0.610372     0.635000      0.790000   \n",
       "Perc5               0.766667     0.615224     0.628333      0.805000   \n",
       "Corr5               0.790000     0.631537     0.605000      0.825000   \n",
       "All imp dims5       0.675000     0.560084     0.618333      0.721667   \n",
       "LR10                0.840000     0.634710     0.621667      0.825000   \n",
       "Perc10              0.818333     0.615198     0.621667      0.823333   \n",
       "Corr10              0.820000     0.623367     0.600000      0.831667   \n",
       "All imp dims10      0.788333     0.598951     0.601667      0.778333   \n",
       "LR25                0.850000     0.623354     0.630000      0.860000   \n",
       "Perc25              0.826667     0.611946     0.606667      0.843333   \n",
       "Corr25              0.841667     0.623328     0.601667      0.843333   \n",
       "All imp dims25      0.821667     0.608760     0.623333      0.831667   \n",
       "LR50                0.860000     0.631419     0.606667      0.851667   \n",
       "Perc50              0.831667     0.587634     0.606667      0.841667   \n",
       "Corr50              0.836667     0.623289     0.596667      0.841667   \n",
       "All imp dims50      0.833333     0.600603     0.621667      0.841667   \n",
       "LR75                0.855000     0.623289     0.603333      0.846667   \n",
       "Perc75              0.845000     0.605507     0.601667      0.856667   \n",
       "Corr75              0.841667     0.610320     0.595000      0.843333   \n",
       "All imp dims75      0.850000     0.629832     0.611667      0.856667   \n",
       "\n",
       "                cam_base  xlm_large  xlm_base  bert_base_u  distilbert_base  \\\n",
       "All dims        0.535309   0.399385  0.586769     0.416883         0.556980   \n",
       "ANOVA           0.531186   0.413846  0.200000     0.485390         0.589388   \n",
       "MI              0.535309   0.406462  0.579077     0.416883         0.552735   \n",
       "All non ind     0.526997   0.444615  0.207692     0.456688         0.564980   \n",
       "LR1             0.502384   0.499692  0.594769     0.449026         0.646122   \n",
       "Perc1           0.558162   0.476615  0.570769     0.409675         0.577633   \n",
       "Corr1           0.512479   0.437846  0.563385     0.449156         0.576653   \n",
       "All imp dims1   0.102083   0.076923  0.115385     0.072727         0.108000   \n",
       "LR5             0.529081   0.468923  0.540308     0.416818         0.621388   \n",
       "Perc5           0.547680   0.446154  0.563385     0.416883         0.593959   \n",
       "Corr5           0.539497   0.437846  0.556000     0.409675         0.593306   \n",
       "All imp dims5   0.506271   0.453538  0.586462     0.464026         0.426286   \n",
       "LR10            0.543578   0.445846  0.548000     0.413247         0.633878   \n",
       "Perc10          0.537371   0.445538  0.571385     0.416883         0.569388   \n",
       "Corr10          0.539454   0.429538  0.556000     0.409610         0.597633   \n",
       "All imp dims10  0.512500   0.461231  0.594154     0.413247         0.581143   \n",
       "LR25            0.535309   0.430154  0.571077     0.416883         0.617551   \n",
       "Perc25          0.541516   0.430462  0.579077     0.416883         0.557061   \n",
       "Corr25          0.535309   0.406154  0.556000     0.416883         0.597633   \n",
       "All imp dims25  0.547745   0.445231  0.556000     0.420455         0.597796   \n",
       "LR50            0.535309   0.422462  0.579077     0.416883         0.589551   \n",
       "Perc50          0.535309   0.383692  0.586769     0.416883         0.557143   \n",
       "Corr50          0.535309   0.391077  0.563692     0.416883         0.577306   \n",
       "All imp dims50  0.537371   0.437846  0.556000     0.416883         0.593796   \n",
       "LR75            0.535309   0.415385  0.586769     0.416883         0.589469   \n",
       "Perc75          0.535309   0.399692  0.579077     0.416883         0.544816   \n",
       "Corr75          0.535309   0.414462  0.571385     0.416883         0.569224   \n",
       "All imp dims75  0.535309   0.399385  0.571385     0.416883         0.561143   \n",
       "\n",
       "                bert_base_c  \n",
       "All dims           0.553143  \n",
       "ANOVA              0.638367  \n",
       "MI                 0.557224  \n",
       "All non ind        0.638367  \n",
       "LR1                0.540653  \n",
       "Perc1              0.536653  \n",
       "Corr1              0.626122  \n",
       "All imp dims1      0.000000  \n",
       "LR5                0.540980  \n",
       "Perc5              0.536735  \n",
       "Corr5              0.634367  \n",
       "All imp dims5      0.342857  \n",
       "LR10               0.524653  \n",
       "Perc10             0.565306  \n",
       "Corr10             0.630449  \n",
       "All imp dims10     0.557224  \n",
       "LR25               0.524653  \n",
       "Perc25             0.549061  \n",
       "Corr25             0.593959  \n",
       "All imp dims25     0.573469  \n",
       "LR50               0.553143  \n",
       "Perc50             0.553143  \n",
       "Corr50             0.565388  \n",
       "All imp dims50     0.557224  \n",
       "LR75               0.557224  \n",
       "Perc75             0.561306  \n",
       "Corr75             0.561306  \n",
       "All imp dims75     0.565388  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_df = pd.DataFrame(avg_accs)\n",
    "accs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba001c6",
   "metadata": {},
   "source": [
    "We can show what is the accuracy gain for each dimension test comparison to using all dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa487cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flau_small_c</th>\n",
       "      <th>flau_base_u</th>\n",
       "      <th>flau_base_c</th>\n",
       "      <th>flau_large_c</th>\n",
       "      <th>cam_base</th>\n",
       "      <th>xlm_large</th>\n",
       "      <th>xlm_base</th>\n",
       "      <th>bert_base_u</th>\n",
       "      <th>distilbert_base</th>\n",
       "      <th>bert_base_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All dims</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANOVA</th>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>-0.004124</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>-0.386769</td>\n",
       "      <td>0.068506</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.027616</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All non ind</th>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>-0.008312</td>\n",
       "      <td>0.045231</td>\n",
       "      <td>-0.379077</td>\n",
       "      <td>0.039805</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR1</th>\n",
       "      <td>-0.136667</td>\n",
       "      <td>-0.034002</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>-0.032925</td>\n",
       "      <td>0.100308</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.089143</td>\n",
       "      <td>-0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc1</th>\n",
       "      <td>-0.163333</td>\n",
       "      <td>-0.035785</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.126667</td>\n",
       "      <td>0.022852</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>-0.007208</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>-0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr1</th>\n",
       "      <td>-0.111667</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>-0.091667</td>\n",
       "      <td>-0.022831</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>-0.023385</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>0.019673</td>\n",
       "      <td>0.072980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims1</th>\n",
       "      <td>-0.715000</td>\n",
       "      <td>-0.169696</td>\n",
       "      <td>-0.363333</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>-0.433226</td>\n",
       "      <td>-0.322462</td>\n",
       "      <td>-0.471385</td>\n",
       "      <td>-0.344156</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-0.553143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR5</th>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>-0.006229</td>\n",
       "      <td>0.069538</td>\n",
       "      <td>-0.046462</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.064408</td>\n",
       "      <td>-0.012163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc5</th>\n",
       "      <td>-0.078333</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>-0.023385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>-0.016408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr5</th>\n",
       "      <td>-0.055000</td>\n",
       "      <td>0.024443</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>-0.007208</td>\n",
       "      <td>0.036327</td>\n",
       "      <td>0.081224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims5</th>\n",
       "      <td>-0.170000</td>\n",
       "      <td>-0.047010</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.128333</td>\n",
       "      <td>-0.029038</td>\n",
       "      <td>0.054154</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>-0.130694</td>\n",
       "      <td>-0.210286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR10</th>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.027616</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>-0.038769</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.076898</td>\n",
       "      <td>-0.028490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc10</th>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.012163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr10</th>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>-0.018333</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.030154</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0.040653</td>\n",
       "      <td>0.077306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims10</th>\n",
       "      <td>-0.056667</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.071667</td>\n",
       "      <td>-0.022809</td>\n",
       "      <td>0.061846</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR25</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>-0.015692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060571</td>\n",
       "      <td>-0.028490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc25</th>\n",
       "      <td>-0.018333</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.031077</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr25</th>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040653</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims25</th>\n",
       "      <td>-0.023333</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.018333</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.020327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR50</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc50</th>\n",
       "      <td>-0.013333</td>\n",
       "      <td>-0.019460</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr50</th>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.012245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims50</th>\n",
       "      <td>-0.011667</td>\n",
       "      <td>-0.006491</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036816</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR75</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032490</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perc75</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>0.008163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corr75</th>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>-0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015077</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.008163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All imp dims75</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.012245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                flau_small_c  flau_base_u  flau_base_c  flau_large_c  \\\n",
       "All dims            0.000000     0.000000     0.000000      0.000000   \n",
       "ANOVA              -0.008333     0.022777     0.008333     -0.006667   \n",
       "MI                 -0.005000     0.027616     0.001667      0.001667   \n",
       "All non ind        -0.006667     0.022738     0.003333     -0.005000   \n",
       "LR1                -0.136667    -0.034002    -0.020000     -0.160000   \n",
       "Perc1              -0.163333    -0.035785     0.010000     -0.126667   \n",
       "Corr1              -0.111667     0.004878     0.018333     -0.091667   \n",
       "All imp dims1      -0.715000    -0.169696    -0.363333     -0.720000   \n",
       "LR5                -0.041667     0.003278     0.041667     -0.060000   \n",
       "Perc5              -0.078333     0.008130     0.035000     -0.045000   \n",
       "Corr5              -0.055000     0.024443     0.011667     -0.025000   \n",
       "All imp dims5      -0.170000    -0.047010     0.025000     -0.128333   \n",
       "LR10               -0.005000     0.027616     0.028333     -0.025000   \n",
       "Perc10             -0.026667     0.008104     0.028333     -0.026667   \n",
       "Corr10             -0.025000     0.016273     0.006667     -0.018333   \n",
       "All imp dims10     -0.056667    -0.008143     0.008333     -0.071667   \n",
       "LR25                0.005000     0.016260     0.036667      0.010000   \n",
       "Perc25             -0.018333     0.004852     0.013333     -0.006667   \n",
       "Corr25             -0.003333     0.016234     0.008333     -0.006667   \n",
       "All imp dims25     -0.023333     0.001665     0.030000     -0.018333   \n",
       "LR50                0.015000     0.024325     0.013333      0.001667   \n",
       "Perc50             -0.013333    -0.019460     0.013333     -0.008333   \n",
       "Corr50             -0.008333     0.016195     0.003333     -0.008333   \n",
       "All imp dims50     -0.011667    -0.006491     0.028333     -0.008333   \n",
       "LR75                0.010000     0.016195     0.010000     -0.003333   \n",
       "Perc75              0.000000    -0.001587     0.008333      0.006667   \n",
       "Corr75             -0.003333     0.003226     0.001667     -0.006667   \n",
       "All imp dims75      0.005000     0.022738     0.018333      0.006667   \n",
       "\n",
       "                cam_base  xlm_large  xlm_base  bert_base_u  distilbert_base  \\\n",
       "All dims        0.000000   0.000000  0.000000     0.000000         0.000000   \n",
       "ANOVA          -0.004124   0.014462 -0.386769     0.068506         0.032408   \n",
       "MI              0.000000   0.007077 -0.007692     0.000000        -0.004245   \n",
       "All non ind    -0.008312   0.045231 -0.379077     0.039805         0.008000   \n",
       "LR1            -0.032925   0.100308  0.008000     0.032143         0.089143   \n",
       "Perc1           0.022852   0.077231 -0.016000    -0.007208         0.020653   \n",
       "Corr1          -0.022831   0.038462 -0.023385     0.032273         0.019673   \n",
       "All imp dims1  -0.433226  -0.322462 -0.471385    -0.344156        -0.448980   \n",
       "LR5            -0.006229   0.069538 -0.046462    -0.000065         0.064408   \n",
       "Perc5           0.012371   0.046769 -0.023385     0.000000         0.036980   \n",
       "Corr5           0.004188   0.038462 -0.030769    -0.007208         0.036327   \n",
       "All imp dims5  -0.029038   0.054154 -0.000308     0.047143        -0.130694   \n",
       "LR10            0.008269   0.046462 -0.038769    -0.003636         0.076898   \n",
       "Perc10          0.002062   0.046154 -0.015385     0.000000         0.012408   \n",
       "Corr10          0.004145   0.030154 -0.030769    -0.007273         0.040653   \n",
       "All imp dims10 -0.022809   0.061846  0.007385    -0.003636         0.024163   \n",
       "LR25            0.000000   0.030769 -0.015692     0.000000         0.060571   \n",
       "Perc25          0.006207   0.031077 -0.007692     0.000000         0.000082   \n",
       "Corr25          0.000000   0.006769 -0.030769     0.000000         0.040653   \n",
       "All imp dims25  0.012436   0.045846 -0.030769     0.003571         0.040816   \n",
       "LR50            0.000000   0.023077 -0.007692     0.000000         0.032571   \n",
       "Perc50          0.000000  -0.015692  0.000000     0.000000         0.000163   \n",
       "Corr50          0.000000  -0.008308 -0.023077     0.000000         0.020327   \n",
       "All imp dims50  0.002062   0.038462 -0.030769     0.000000         0.036816   \n",
       "LR75            0.000000   0.016000  0.000000     0.000000         0.032490   \n",
       "Perc75          0.000000   0.000308 -0.007692     0.000000        -0.012163   \n",
       "Corr75          0.000000   0.015077 -0.015385     0.000000         0.012245   \n",
       "All imp dims75  0.000000   0.000000 -0.015385     0.000000         0.004163   \n",
       "\n",
       "                bert_base_c  \n",
       "All dims           0.000000  \n",
       "ANOVA              0.085224  \n",
       "MI                 0.004082  \n",
       "All non ind        0.085224  \n",
       "LR1               -0.012490  \n",
       "Perc1             -0.016490  \n",
       "Corr1              0.072980  \n",
       "All imp dims1     -0.553143  \n",
       "LR5               -0.012163  \n",
       "Perc5             -0.016408  \n",
       "Corr5              0.081224  \n",
       "All imp dims5     -0.210286  \n",
       "LR10              -0.028490  \n",
       "Perc10             0.012163  \n",
       "Corr10             0.077306  \n",
       "All imp dims10     0.004082  \n",
       "LR25              -0.028490  \n",
       "Perc25            -0.004082  \n",
       "Corr25             0.040816  \n",
       "All imp dims25     0.020327  \n",
       "LR50               0.000000  \n",
       "Perc50             0.000000  \n",
       "Corr50             0.012245  \n",
       "All imp dims50     0.004082  \n",
       "LR75               0.004082  \n",
       "Perc75             0.008163  \n",
       "Corr75             0.008163  \n",
       "All imp dims75     0.012245  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gains_df = (accs_df - accs_df.loc['All dims'])\n",
    "gains_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b998e",
   "metadata": {},
   "source": [
    "Here are the dimension groups and the accuracy gain this dimension group provides over all dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c923df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c LR50 0.015000000000000013\n",
      "flau_base_u MI 0.027616050354051902\n",
      "flau_base_c LR5 0.04166666666666663\n",
      "flau_large_c LR25 0.010000000000000009\n",
      "cam_base Perc1 0.022852233676975975\n",
      "xlm_large LR1 0.10030769230769226\n",
      "xlm_base LR1 0.008000000000000007\n",
      "bert_base_u ANOVA 0.06850649350649352\n",
      "distilbert_base LR1 0.08914285714285708\n",
      "bert_base_c ANOVA 0.08522448979591823\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(labels[i], gains_df.idxmax()[i], gains_df.loc[gains_df.idxmax()[i], labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cde76344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c LR50 0.86\n",
      "flau_base_u MI 0.634710201940729\n",
      "flau_base_c LR5 0.635\n",
      "flau_large_c LR25 0.86\n",
      "cam_base Perc1 0.5581615120274914\n",
      "xlm_large LR1 0.49969230769230766\n",
      "xlm_base LR1 0.5947692307692308\n",
      "bert_base_u ANOVA 0.48538961038961037\n",
      "distilbert_base LR1 0.6461224489795917\n",
      "bert_base_c ANOVA 0.6383673469387754\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(labels[i], accs_df.idxmax()[i], accs_df.loc[accs_df.idxmax()[i], labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85e4c9",
   "metadata": {},
   "source": [
    "For each fold find dimensions with the highest accuracy, and pick dimensions appeared in all 5 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbe2ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dims = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0789e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_cand_accs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63da0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 95 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.8733333333333334\n",
      "flau_base_u: 5 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.6184500393391031\n",
      "flau_base_c: 1 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.6033333333333333\n",
      "flau_large_c: 63 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.85\n",
      "cam_base: 0 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.0\n",
      "xlm_large: 0 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.0\n",
      "xlm_base: 1 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.21538461538461537\n",
      "bert_base_u: 0 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.0\n",
      "distilbert_base: 1 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.5891428571428572\n",
      "bert_base_c: 6 dimensions repeated in 5 folds\n",
      "Average accuracy: 0.6831020408163265\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels)):\n",
    "    bd = []\n",
    "    for j in range(n_folds):\n",
    "        best_dim_group = ''\n",
    "        best_acc = 0\n",
    "        for dim_group in accs[labels[i]].keys():\n",
    "            if accs[labels[i]][dim_group][j] > best_acc:\n",
    "                best_dim_group = dim_group\n",
    "                best_acc = accs[labels[i]][dim_group][j]\n",
    "        bd.extend(dims[labels[i]][best_dim_group][j])\n",
    "    \n",
    "    # Find dimensions that appeared within dimensions with the highest accuracy in all 5 folds\n",
    "    d, c = np.unique(bd, return_counts=True)\n",
    "    dim_cand = [x[0] for x in zip(d, c) if x[1] >= 5]\n",
    "    best_dims[labels[i]] = dim_cand\n",
    "    print(f'{labels[i]}: {len(dim_cand)} dimensions repeated in 5 folds')\n",
    "\n",
    "    # For each fold build a prediction and calculate accuracy\n",
    "    cand_accs = []\n",
    "    for j in range(n_folds):\n",
    "        med0_cand = X_noun_train[i][j][y_noun_train[i][j] == 0][dim_cand].median()\n",
    "        med1_cand = X_noun_train[i][j][y_noun_train[i][j] == 1][dim_cand].median()\n",
    "        \n",
    "        mae0_cand = X_noun_test[i][j][dim_cand].apply(lambda x: mean_absolute_error(med0_cand, x), axis=1)\n",
    "        mae1_cand = X_noun_test[i][j][dim_cand].apply(lambda x: mean_absolute_error(med1_cand, x), axis=1)\n",
    "        \n",
    "        y_pred_cand = (mae0_cand > mae1_cand).apply(int)\n",
    "        if any(y_pred_cand):\n",
    "            cand_accs.append(accuracy_score(y_true=y_noun_test[i][j], y_pred=y_pred_cand))\n",
    "        else:\n",
    "            cand_accs.append(0)\n",
    "    dim_cand_accs[labels[i]] = cand_accs\n",
    "    print(f'Average accuracy: {np.average(cand_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f166354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/best_results/semantic_person_dims.pickle', 'wb') as f:\n",
    "    pickle.dump(dims, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91e4d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/best_results/semantic_person_accs.pickle', 'wb') as f:\n",
    "    pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80bac678",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/best_results/semantic_person_medians.pickle', 'wb') as f:\n",
    "    pickle.dump(medians, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ba37b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af44fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
