{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac006e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f48d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import aabcc, sig_props, correlation, lr, perceptron, kmeans_1dim, \\\n",
    "                     score_comparison, run_tests, report, dimensions_report, repeated_dimensions, \\\n",
    "                    kmeans_multi_dim\n",
    "from preparation import prepare_dataset, read_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd6ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e895408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b537ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f26bf",
   "metadata": {},
   "source": [
    "Due to big size of WE files they are not uploaded to Github, but can instead be downloaded [here](https://drive.google.com/drive/folders/10Ea62GRlq4t7bq-nK9tPtYFu0kbCciey?usp=sharing).\n",
    "\n",
    "The code below expects a folder \"Data\" in the root folder containing all the information from the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8faf03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert/camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [m['label'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba233d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_with_features = read_datasets(\n",
    "                            path = '../Data',\n",
    "                            model_labels = labels,\n",
    "                            file_name = 'all_unique_pos_we.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091c3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>Number</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D</th>\n",
       "      <td>5.531172</td>\n",
       "      <td>-8.963815</td>\n",
       "      <td>1.558320</td>\n",
       "      <td>3.143550</td>\n",
       "      <td>-5.372142</td>\n",
       "      <td>-0.174002</td>\n",
       "      <td>-1.124767</td>\n",
       "      <td>5.729996</td>\n",
       "      <td>-2.367389</td>\n",
       "      <td>4.247167</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.374313</td>\n",
       "      <td>-7.161043</td>\n",
       "      <td>2.704918</td>\n",
       "      <td>-4.613951</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>2D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>3.969331</td>\n",
       "      <td>-6.442656</td>\n",
       "      <td>1.451928</td>\n",
       "      <td>3.447791</td>\n",
       "      <td>-4.224664</td>\n",
       "      <td>-1.029557</td>\n",
       "      <td>-3.664733</td>\n",
       "      <td>4.911453</td>\n",
       "      <td>0.223902</td>\n",
       "      <td>5.621365</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.463473</td>\n",
       "      <td>-10.008975</td>\n",
       "      <td>2.005870</td>\n",
       "      <td>-2.951385</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>3D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>5.617864</td>\n",
       "      <td>-6.741737</td>\n",
       "      <td>2.519838</td>\n",
       "      <td>-3.914263</td>\n",
       "      <td>2.801907</td>\n",
       "      <td>-1.182259</td>\n",
       "      <td>4.435670</td>\n",
       "      <td>-1.600746</td>\n",
       "      <td>-0.582458</td>\n",
       "      <td>1.409745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>0.809533</td>\n",
       "      <td>-10.274058</td>\n",
       "      <td>2.984729</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aba</th>\n",
       "      <td>4.914313</td>\n",
       "      <td>-6.923126</td>\n",
       "      <td>-3.848757</td>\n",
       "      <td>5.110574</td>\n",
       "      <td>-2.516107</td>\n",
       "      <td>-4.938292</td>\n",
       "      <td>2.373581</td>\n",
       "      <td>-2.756590</td>\n",
       "      <td>2.567556</td>\n",
       "      <td>2.412183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979258</td>\n",
       "      <td>-2.605051</td>\n",
       "      <td>-7.204095</td>\n",
       "      <td>-4.154819</td>\n",
       "      <td>singular</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aba</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaisse</th>\n",
       "      <td>4.652038</td>\n",
       "      <td>-4.028066</td>\n",
       "      <td>0.883200</td>\n",
       "      <td>4.782077</td>\n",
       "      <td>-2.294614</td>\n",
       "      <td>-3.894452</td>\n",
       "      <td>-0.810279</td>\n",
       "      <td>-0.713935</td>\n",
       "      <td>4.819910</td>\n",
       "      <td>4.090150</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.542219</td>\n",
       "      <td>-4.662947</td>\n",
       "      <td>-0.546076</td>\n",
       "      <td>-1.836028</td>\n",
       "      <td>singular</td>\n",
       "      <td>feminine</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "Word                                                                            \n",
       "2D       5.531172 -8.963815  1.558320  3.143550 -5.372142 -0.174002 -1.124767   \n",
       "3D       3.969331 -6.442656  1.451928  3.447791 -4.224664 -1.029557 -3.664733   \n",
       "aa       5.617864 -6.741737  2.519838 -3.914263  2.801907 -1.182259  4.435670   \n",
       "aba      4.914313 -6.923126 -3.848757  5.110574 -2.516107 -4.938292  2.373581   \n",
       "abaisse  4.652038 -4.028066  0.883200  4.782077 -2.294614 -3.894452 -0.810279   \n",
       "\n",
       "                7         8         9  ...       508        509        510  \\\n",
       "Word                                   ...                                   \n",
       "2D       5.729996 -2.367389  4.247167  ... -2.374313  -7.161043   2.704918   \n",
       "3D       4.911453  0.223902  5.621365  ... -1.463473 -10.008975   2.005870   \n",
       "aa      -1.600746 -0.582458  1.409745  ... -0.108588   0.809533 -10.274058   \n",
       "aba     -2.756590  2.567556  2.412183  ... -0.979258  -2.605051  -7.204095   \n",
       "abaisse -0.713935  4.819910  4.090150  ... -7.542219  -4.662947  -0.546076   \n",
       "\n",
       "              511      Number     Gender    Lemma   POS  Tense  Person  \n",
       "Word                                                                    \n",
       "2D      -4.613951  invariable   feminine       2D  NOUN    NaN     NaN  \n",
       "3D      -2.951385  invariable   feminine       3D  NOUN    NaN     NaN  \n",
       "aa       2.984729  invariable  masculine       aa  NOUN    NaN     NaN  \n",
       "aba     -4.154819    singular  masculine      aba  NOUN    NaN     NaN  \n",
       "abaisse -1.836028    singular   feminine  abaisse  NOUN    NaN     NaN  \n",
       "\n",
       "[5 rows x 518 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_with_features[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 6 extra feautres in addition to embedding dimensions in the file: number, gender, lemma, pos, tense,\n",
    "# person\n",
    "feature_col_count = 6\n",
    "\n",
    "# Feature to investigate in this notebook\n",
    "feature = 'Number'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da06780",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d134",
   "metadata": {},
   "source": [
    "1. Exclude datapoints with undefined feature values (e.g. Gender = `invariable`)\n",
    "2. Encode a grammatical feature as binary (e.g. Gender = 0 if masculine and 1 if feminine) (feature vector)\n",
    "3. Shuffle the data set\n",
    "4. Separate the dataset into 80% \"training\" and 20% test data\n",
    "5. For each dimension in the test dataset measure if the dimension values are dependent on the grammatic feature\n",
    "* Using [ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html): The data is split into 2 samples, all dimension values when the grammatical feature is 0 and when it's equal to 1.\n",
    "* Using [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "6. For each dimension highlighted during step #5 find medians for 2 subgroups: when the grammatical feature == 0 and when it == 1.\n",
    "7. For each word in the test dataset, find the predicted label using MSE using medians of the dimensions from #6.\n",
    "8. Compute accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bbb6b",
   "metadata": {},
   "source": [
    "We assume that achieved accuracies can be an efficient way of comparing the quality of grammatical information encoding in the word embeddings.\n",
    "\n",
    "The experiments for `Gender` and `Number` will be performed for \"nouns only\", \"adjectives only\" and \"nouns and adjectives\" combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a760",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bc1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the experiment with nouns only\n",
    "pos = ['NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07b0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noun_train = []\n",
    "y_noun_train = []\n",
    "\n",
    "X_noun_test = []\n",
    "y_noun_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70563c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Number != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_noun_train.append(xtr)\n",
    "    X_noun_test.append(xtst)\n",
    "    \n",
    "    y_noun_train.append(ytr)\n",
    "    y_noun_test.append(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ddfb0",
   "metadata": {},
   "source": [
    "### Compute ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eed918",
   "metadata": {},
   "source": [
    "We split each dimension into 2 samples: feminine nouns and masculine nouns. ANOVA test is used to assess if the population means are the same.\n",
    "\n",
    "If the population means are not the same, we can make an assumption that the gender information affects the distribution of values in the given dimension.\n",
    "\n",
    "If p-value < 0.001, reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3596e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73edb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cc630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_noun_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims.append(model_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5b5d3",
   "metadata": {},
   "source": [
    "We can see that a very large amount of dimensions appear to be highlighted by the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d86239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "Total dimensions 512\n",
      "ANOVA dimensions: 361\n",
      "\n",
      "flau_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 253\n",
      "\n",
      "flau_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 444\n",
      "\n",
      "flau_large_c:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 810\n",
      "\n",
      "cam_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}:\\nTotal dimensions {len(X_noun_train[i].columns)}\\nANOVA dimensions: {len(anova_dims[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac08a30",
   "metadata": {},
   "source": [
    "We can see that in comparison with gender information ANOVA highlights more dimensions as dependent for FlauBERT.\n",
    "\n",
    "Due to CamemBERT's tokenization where frequently an ending signinfying multiplicity is cut off, the number of highlighted dimensions is extremely low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867da94",
   "metadata": {},
   "source": [
    "### Compute Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488513e3",
   "metadata": {},
   "source": [
    "If mutual information is 0, we can consider that a given dimension is independent from Gender information.\n",
    "\n",
    "If MI > 0, we can't consider the dimension completely independent and it could encode the Gender information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad7be602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "455215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_noun_train[i], y_noun_train[i], discrete_features=[False]*len(X_noun_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a327f1f",
   "metadata": {},
   "source": [
    "Overall, threshold of 0 finds much more dimensions. This could be potentially addressed with a different threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05902a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "    Total dimensions 512\n",
      "    ANOVA dimensions: 361\n",
      "    Mutual Information dimension: 390\n",
      "\n",
      "\n",
      "flau_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 253\n",
      "    Mutual Information dimension: 472\n",
      "\n",
      "\n",
      "flau_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 444\n",
      "    Mutual Information dimension: 537\n",
      "\n",
      "\n",
      "flau_large_c:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 810\n",
      "    Mutual Information dimension: 784\n",
      "\n",
      "\n",
      "cam_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 5\n",
      "    Mutual Information dimension: 412\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f\"\"\"{models[i]['label']}:\n",
    "    Total dimensions {len(X_noun_train[i].columns)}\n",
    "    ANOVA dimensions: {len(anova_dims[i])}\n",
    "    Mutual Information dimension: {len(mi_dims[i])}\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af43dc",
   "metadata": {},
   "source": [
    "For now, for each model we select only dimensions that are potentially dependent on the gender information and found by the both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d64f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims = [set(anova_dims[i]).intersection(mi_dims[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a713",
   "metadata": {},
   "source": [
    "Final number of dimensions that we can consider not independent from the gender information for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae8ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 301\n",
      "flau_base_u: 170\n",
      "flau_base_c: 350\n",
      "flau_large_c: 677\n",
      "cam_base: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42aabdc",
   "metadata": {},
   "source": [
    "Note that for FlauBERT large the number of highlighted dimensions is more than half of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666804dc",
   "metadata": {},
   "source": [
    "### Compute medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07503183",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cfc73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(mi_annova_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(mi_annova_dims[i])].median()\n",
    "    medians.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d276c5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_0</th>\n",
       "      <th>median_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.524001</td>\n",
       "      <td>0.498422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.474348</td>\n",
       "      <td>0.479169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.494020</td>\n",
       "      <td>0.511124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.484454</td>\n",
       "      <td>0.461748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.529566</td>\n",
       "      <td>0.535599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.437954</td>\n",
       "      <td>0.460126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.484993</td>\n",
       "      <td>0.501390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.591778</td>\n",
       "      <td>0.577745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.432726</td>\n",
       "      <td>0.450140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.473807</td>\n",
       "      <td>0.470131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     median_0  median_1\n",
       "356  0.524001  0.498422\n",
       "573  0.474348  0.479169\n",
       "104  0.494020  0.511124\n",
       "381  0.484454  0.461748\n",
       "221  0.529566  0.535599\n",
       "..        ...       ...\n",
       "626  0.437954  0.460126\n",
       "449  0.484993  0.501390\n",
       "207  0.591778  0.577745\n",
       "33   0.432726  0.450140\n",
       "288  0.473807  0.470131\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe5f06",
   "metadata": {},
   "source": [
    "### Predict label for test set using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ae32713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4749af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_squared_error(medians[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_squared_error(medians[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44bc8",
   "metadata": {},
   "source": [
    "### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a5128ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.921301775147929\n",
      "flau_base_u: Accuracy 0.6774346793349169\n",
      "flau_base_c: Accuracy 0.6041420118343195\n",
      "flau_large_c: Accuracy 0.9467455621301775\n",
      "cam_base: Accuracy 0.5493827160493827\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_noun_test[i], y_preds[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304fd3f",
   "metadata": {},
   "source": [
    "# Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fd2f3",
   "metadata": {},
   "source": [
    "Repeat all steps but for adjectives only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a9c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d031f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adj_train = []\n",
    "y_adj_train = []\n",
    "\n",
    "X_adj_test = []\n",
    "y_adj_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f3d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_adj_train.append(xtr)\n",
    "    X_adj_test.append(xtst)\n",
    "    \n",
    "    y_adj_train.append(ytr)\n",
    "    y_adj_test.append(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00d5a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2835afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_adj_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_adj.append(model_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6290e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53b8ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_adj_train[i], y_adj_train[i], discrete_features=[False]*len(X_adj_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_adj.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1c839f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims_adj = [set(anova_dims_adj[i]).intersection(mi_dims_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d56f9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc2ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_adj.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c439ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac68a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_squared_error(medians_adj[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_squared_error(medians_adj[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_adj.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91257f",
   "metadata": {},
   "source": [
    "Here are the accuracies for adjectives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d274799",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj = [accuracy_score(y_adj_test[i], y_preds_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dfeb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.3622448979591837\n",
      "flau_base_u: Accuracy 0.20770877944325483\n",
      "flau_base_c: Accuracy 0.3163265306122449\n",
      "flau_large_c: Accuracy 0.41581632653061223\n",
      "cam_base: Accuracy 0.12612612612612611\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_adj_test[i], y_preds_adj[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8bff8",
   "metadata": {},
   "source": [
    "# Adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d932b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.28657686948444033\n",
      "flau_base_u: Accuracy 0.2530841121495327\n",
      "flau_base_c: Accuracy 0.21319089642359498\n",
      "flau_large_c: Accuracy 0.32326985601486297\n",
      "cam_base: Accuracy 0.12142857142857143\n"
     ]
    }
   ],
   "source": [
    "pos = ['ADJ', 'NOUN']\n",
    "\n",
    "X_na_train = []\n",
    "y_na_train = []\n",
    "\n",
    "X_na_test = []\n",
    "y_na_test = []\n",
    "\n",
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_na_train.append(xtr)\n",
    "    X_na_test.append(xtst)\n",
    "    \n",
    "    y_na_train.append(ytr)\n",
    "    y_na_test.append(ytst)\n",
    "\n",
    "anova_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_na_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_na.append(model_dims)\n",
    "\n",
    "mi_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_na_train[i], y_na_train[i], discrete_features=[False]*len(X_na_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_na.append(non_indep_dims)\n",
    "\n",
    "mi_annova_dims_na = [set(anova_dims_na[i]).intersection(mi_dims_na[i]) for i in range(len(models))]\n",
    "\n",
    "medians_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0][list(mi_annova_dims_na[i])].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1][list(mi_annova_dims_na[i])].median()\n",
    "    medians_na.append(medians_df)\n",
    "\n",
    "y_preds_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mse0 = X_na_test[i][list(mi_annova_dims_na[i])].apply(lambda x: mean_squared_error(medians_na[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_na_test[i][list(mi_annova_dims_na[i])].apply(lambda x: mean_squared_error(medians_na[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_na.append(y_pred)\n",
    "\n",
    "accs_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_na_test[i], y_preds_na[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330f3fa",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54cc57",
   "metadata": {},
   "source": [
    "We can see that the accuracy is much higher for classifying nouns than adjectives.\n",
    "\n",
    "For some reason, the accuracy for predictions on adjectives is below random choice.\n",
    "\n",
    "Once again FlauBERT small despite much smaller size is showing comparable accuracy with FlauBERT large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773ccae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
