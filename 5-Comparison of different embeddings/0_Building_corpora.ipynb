{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2957a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02562512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from we import initiate_model, get_we, create_we_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b49e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44842efb",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27962168",
   "metadata": {},
   "source": [
    "The code will load a Transformer model from Hugging Face library.\n",
    "It is expected that the model can be loaded using `AutoModelForMaskedLM` function of the Hugging Face library and its tokenizer can be initiated using `AutoTokenizer`.\n",
    "\n",
    "This can be confirmed on [the model's page](https://huggingface.co/flaubert/flaubert_base_uncased) in the Hugging Face library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4746fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all models to compare\n",
    "# Since model names can be quite long, label can be used to reference it in the reports. \n",
    "# If label is not present in the model object, its full name will be used in the reports instead.\n",
    "# If label is present in the object, it can't be an empty string.\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca27b55",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da017a",
   "metadata": {},
   "source": [
    "In our case we build dataset by getting all nouns, verbs and adverbs from Morphalou and their grammatical information.\n",
    "Then we attempt to obtain a word embedding for each of the words. If it exists (meaning that tokenizer tokenizes the word as one token), it's added to the dataset with the following information:\n",
    "- Word \n",
    "- PoS\n",
    "- Grammatical information if present\n",
    "- All dimensions of WE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303064a8",
   "metadata": {},
   "source": [
    "If there is any word that is both masculine and feminine, or other 2 grammatical characteristics at the same time, it was excluded from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_verbs = pd.read_csv('../Data/Morphalou/all_verbs_v2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e146d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nouns = pd.read_csv('../Data/Morphalou/all_nouns_v2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6996db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adjs = pd.read_csv('../Data/Morphalou/all_adjs_v2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae173959",
   "metadata": {},
   "source": [
    "Build the dataset of WE with features for each model in the list above for Verbs, Nouns and Adjectives.\n",
    "\n",
    "Runtime per model is ~1-1.5 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be394fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating model flaubert/flaubert_base_uncased:\n",
      "Done\n",
      "\n",
      "Generating WE for nouns:\n",
      ".........................................................................................................................................................................................\n",
      "Nouns WE are being stored in the file: ../Data/flau_base_u/all_nouns_we.csv\n",
      "\n",
      "Generating WE for verbs:\n",
      ".................................................................................................................................................................................................................................................................................................................................\n",
      "Verbs WE are being stored in the file: ../Data/flau_base_u/all_verbs_we.csv\n",
      "\n",
      "Generating WE for adjs:\n",
      "...................................................................................................\n",
      "Adjs WE are being stored in the file: ../Data/flau_base_u/all_adjs_we.csv\n",
      "============================\n",
      "Initiating model flaubert/flaubert_base_cased:\n",
      "Done\n",
      "\n",
      "Generating WE for nouns:\n",
      ".........................................................................................................................................................................................\n",
      "Nouns WE are being stored in the file: ../Data/flau_base_c/all_nouns_we.csv\n",
      "\n",
      "Generating WE for verbs:\n",
      ".................................................................................................................................................................................................................................................................................................................................\n",
      "Verbs WE are being stored in the file: ../Data/flau_base_c/all_verbs_we.csv\n",
      "\n",
      "Generating WE for adjs:\n",
      "...................................................................................................\n",
      "Adjs WE are being stored in the file: ../Data/flau_base_c/all_adjs_we.csv\n",
      "============================\n",
      "Initiating model flaubert/flaubert_large_cased:\n",
      "Done\n",
      "\n",
      "Generating WE for nouns:\n",
      ".........................................................................................................................................................................................\n",
      "Nouns WE are being stored in the file: ../Data/flau_large_c/all_nouns_we.csv\n",
      "\n",
      "Generating WE for verbs:\n",
      ".................................................................................................................................................................................................................................................................................................................................\n",
      "Verbs WE are being stored in the file: ../Data/flau_large_c/all_verbs_we.csv\n",
      "\n",
      "Generating WE for adjs:\n",
      "...................................................................................................\n",
      "Adjs WE are being stored in the file: ../Data/flau_large_c/all_adjs_we.csv\n",
      "============================\n",
      "Initiating model camembert-base:\n",
      "Done\n",
      "\n",
      "Generating WE for nouns:\n",
      ".........................................................................................................................................................................................\n",
      "Nouns WE are being stored in the file: ../Data/cam_base/all_nouns_we.csv\n",
      "\n",
      "Generating WE for verbs:\n",
      ".................................................................................................................................................................................................................................................................................................................................\n",
      "Verbs WE are being stored in the file: ../Data/cam_base/all_verbs_we.csv\n",
      "\n",
      "Generating WE for adjs:\n",
      "...................................................................................................\n",
      "Adjs WE are being stored in the file: ../Data/cam_base/all_adjs_we.csv\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for model in models[]:\n",
    "    # Get the label of the model if it's present, otherwise get its name.\n",
    "    # Any slashes in the names are replaced with empty strings to work with file saving.\n",
    "    model_label = re.sub('/', '', model.get('label', model['name']))\n",
    "    file_path = f'../Data/{model_label}'\n",
    "    # Create the folder for file storage if it's not created yet.\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    \n",
    "    print(f'Initiating model {model[\"name\"]}:')\n",
    "    m, t = initiate_model(model['name'])\n",
    "    print('Done')\n",
    "    \n",
    "    print('\\nGenerating WE for nouns:')\n",
    "    nouns_we_df = create_we_df(m, t, all_nouns, progress=True)\n",
    "    print(f'\\nNouns WE are being stored in the file: {file_path}/all_nouns_we.csv')\n",
    "    nouns_we_df.to_csv(f'{file_path}/all_nouns_we.csv')\n",
    "\n",
    "    print('\\nGenerating WE for verbs:')\n",
    "    verbs_we_df = create_we_df(m, t, all_verbs, progress=True)\n",
    "    print(f'\\nVerbs WE are being stored in the file: {file_path}/all_verbs_we.csv')\n",
    "    verbs_we_df.to_csv(f'{file_path}/all_verbs_we.csv')\n",
    "    \n",
    "    print('\\nGenerating WE for adjs:')\n",
    "    adjs_we_df = create_we_df(m, t, all_adjs, progress=True)\n",
    "    print(f'\\nAdjs WE are being stored in the file: {file_path}/all_adjs_we.csv')\n",
    "    adjs_we_df.to_csv(f'{file_path}/all_adjs_we.csv')\n",
    "    \n",
    "    print('============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac720c",
   "metadata": {},
   "source": [
    "# Corpora sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd6f46",
   "metadata": {},
   "source": [
    "Below you will find the sizes of WE datasets for each PoS and for each model: it represents how many unique wordforms have a WE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c16d3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flau_small_c</td>\n",
       "      <td>15183</td>\n",
       "      <td>5425</td>\n",
       "      <td>8881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flau_base_u</td>\n",
       "      <td>18489</td>\n",
       "      <td>6377</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flau_base_c</td>\n",
       "      <td>15183</td>\n",
       "      <td>5425</td>\n",
       "      <td>8881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flau_large_c</td>\n",
       "      <td>15183</td>\n",
       "      <td>5425</td>\n",
       "      <td>8881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cam_base</td>\n",
       "      <td>10594</td>\n",
       "      <td>3852</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Nouns  Verbs   Adjs\n",
       "0  flau_small_c  15183   5425   8881\n",
       "1   flau_base_u  18489   6377  10460\n",
       "2   flau_base_c  15183   5425   8881\n",
       "3  flau_large_c  15183   5425   8881\n",
       "4      cam_base  10594   3852   6400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = []\n",
    "\n",
    "for m in models:\n",
    "    model_label = re.sub('/', '', m.get('label', m['name']))\n",
    "    file_path = f'../Data/{model_label}'\n",
    "    \n",
    "    noun_size = len(pd.read_csv(f'{file_path}/all_nouns_we.csv', index_col=0))\n",
    "    verb_size = len(pd.read_csv(f'{file_path}/all_verbs_we.csv', index_col=0))\n",
    "    adj_size = len(pd.read_csv(f'{file_path}/all_adjs_we.csv', index_col=0))\n",
    "    e\n",
    "    sizes.append({\n",
    "        'Model': model_label,\n",
    "        'Nouns': noun_size,\n",
    "        'Verbs': verb_size,\n",
    "        'Adjs': adj_size\n",
    "    })\n",
    "    \n",
    "sizes_df = pd.DataFrame(sizes)\n",
    "\n",
    "sizes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
