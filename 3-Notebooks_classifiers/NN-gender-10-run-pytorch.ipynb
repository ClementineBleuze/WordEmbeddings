{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data: NOUN, ADJ, and both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nouns_we = pd.read_csv('../Data/FlauBERT_WE/all_nouns_we.csv').drop(columns=[\"number\"])\n",
    "df_adj_we = pd.read_csv('../Data/FlauBERT_WE/all_adjectives_we.csv').drop(columns = \"number\")\n",
    "df_both_we = pd.concat([df_nouns_we, df_adj_we], ignore_index=True)\n",
    "\n",
    "# target : gender\n",
    "Y_gd_N = df_nouns_we[\"gender\"].apply(lambda x: 1 if x == \"masculine\" else 0)\n",
    "Y_gd_A = df_adj_we[\"gender\"].apply(lambda x: 1 if x == \"masculine\" else 0)\n",
    "Y_gd_both = df_both_we[\"gender\"].apply(lambda x: 1 if x == \"masculine\" else 0)\n",
    "\n",
    "# features : word embeddings dimensions\n",
    "X_gd_N = df_nouns_we.drop(columns=[\"Word\", \"gender\"])\n",
    "X_gd_A = df_adj_we.drop(columns=[\"Word\", \"gender\"])\n",
    "X_gd_both = df_both_we.drop(columns = [\"Word\", \"gender\"] )\n",
    "\n",
    "# normalize data to be between 0 and 1\n",
    "X_gd_N = (X_gd_N - X_gd_N.min()) / (X_gd_N.max() - X_gd_N.min())\n",
    "X_gd_A = (X_gd_A - X_gd_A.min()) / (X_gd_A.max() - X_gd_A.min())\n",
    "X_gd_both = (X_gd_both - X_gd_both.min()) / (X_gd_both.max() - X_gd_both.min())\n",
    "\n",
    "# split data into train and test sets\n",
    "X_gd_N_train, X_gd_N_test, Y_gd_N_train, Y_gd_N_test = train_test_split(X_gd_N, Y_gd_N, test_size=0.2, random_state=42)\n",
    "X_gd_A_train, X_gd_A_test, Y_gd_A_train, Y_gd_A_test = train_test_split(X_gd_A, Y_gd_A, test_size=0.2, random_state=42)\n",
    "X_gd_both_train, X_gd_both_test, Y_gd_both_train, Y_gd_both_test = train_test_split(X_gd_both, Y_gd_both, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [X_gd_N_train, X_gd_A_train, X_gd_both_train]\n",
    "test_features = [X_gd_N_test, X_gd_A_test, X_gd_both_test]\n",
    "train_targets = [Y_gd_N_train, Y_gd_A_train, Y_gd_both_train]\n",
    "test_targets = [Y_gd_N_test, Y_gd_A_test, Y_gd_both_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "train_features = [torch.tensor(x.values).float() for x in train_features]\n",
    "test_features = [torch.tensor(x.values).float() for x in test_features]\n",
    "train_targets = [torch.tensor(x.values).long() for x in train_targets]\n",
    "test_targets = [torch.tensor(x.values).long() for x in test_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Gender: Noun', 'Gender: Adj', 'Gender: Noun + Adj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/dsfsd5r52yn9jjjsj3yn90gr0000gn/T/ipykernel_5024/2087089768.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_features = [torch.tensor(x).float() for x in train_features]\n",
      "/var/folders/wp/dsfsd5r52yn9jjjsj3yn90gr0000gn/T/ipykernel_5024/2087089768.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_features = [torch.tensor(x).float() for x in test_features]\n",
      "/var/folders/wp/dsfsd5r52yn9jjjsj3yn90gr0000gn/T/ipykernel_5024/2087089768.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_targets = [torch.tensor(x).long() for x in train_targets]\n",
      "/var/folders/wp/dsfsd5r52yn9jjjsj3yn90gr0000gn/T/ipykernel_5024/2087089768.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_targets = [torch.tensor(x).long() for x in test_targets]\n"
     ]
    }
   ],
   "source": [
    "# convert to tensors\n",
    "train_features = [torch.tensor(x).float() for x in train_features]\n",
    "test_features = [torch.tensor(x).float() for x in test_features]\n",
    "train_targets = [torch.tensor(x).long() for x in train_targets]\n",
    "test_targets = [torch.tensor(x).long() for x in test_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# the TensorDataset is a ready to use class to represent your data as list of tensors. \n",
    "# Note that input_features and labels must match on the length of the first dimension\n",
    "train_sets = [TensorDataset(X_train, Y_train) for X_train, Y_train in zip(train_features, train_targets)]\n",
    "test_sets = [TensorDataset(X_valid, Y_valid) for X_valid, Y_valid in zip(test_features, test_targets)]\n",
    "\n",
    "# DataLoader shuffles and batches the data and load its in parallel using multiprocessing workers\n",
    "train_loaders = [DataLoader(train_set, batch_size=32, shuffle=True) for train_set in train_sets]\n",
    "test_loaders = [DataLoader(test_set, batch_size=32) for test_set in test_sets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [[], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training model:  Gender: Noun, run 0\n",
      "--Epoch  0  Loss :  0.6518369913101196\n",
      "--Epoch  10  Loss :  0.4662286043167114\n",
      " Training model:  Gender: Adj, run 0\n",
      "--Epoch  0  Loss :  0.6257043480873108\n",
      "--Epoch  10  Loss :  0.41980743408203125\n",
      " Training model:  Gender: Noun + Adj, run 0\n",
      "--Epoch  0  Loss :  0.5905786752700806\n",
      "--Epoch  10  Loss :  0.43220603466033936\n",
      " Training model:  Gender: Noun, run 1\n",
      "--Epoch  0  Loss :  0.6511135697364807\n",
      "--Epoch  10  Loss :  0.567952036857605\n",
      " Training model:  Gender: Adj, run 1\n",
      "--Epoch  0  Loss :  0.6755850315093994\n",
      "--Epoch  10  Loss :  0.47971639037132263\n",
      " Training model:  Gender: Noun + Adj, run 1\n",
      "--Epoch  0  Loss :  0.6628757119178772\n",
      "--Epoch  10  Loss :  0.3877723515033722\n",
      " Training model:  Gender: Noun, run 2\n",
      "--Epoch  0  Loss :  0.7195064425468445\n",
      "--Epoch  10  Loss :  0.4591420590877533\n",
      " Training model:  Gender: Adj, run 2\n",
      "--Epoch  0  Loss :  0.5874132513999939\n",
      "--Epoch  10  Loss :  0.4571899473667145\n",
      " Training model:  Gender: Noun + Adj, run 2\n",
      "--Epoch  0  Loss :  0.6336519718170166\n",
      "--Epoch  10  Loss :  0.4034269452095032\n",
      " Training model:  Gender: Noun, run 3\n",
      "--Epoch  0  Loss :  0.6489534974098206\n",
      "--Epoch  10  Loss :  0.4662748873233795\n",
      " Training model:  Gender: Adj, run 3\n",
      "--Epoch  0  Loss :  0.6779792308807373\n",
      "--Epoch  10  Loss :  0.37601831555366516\n",
      " Training model:  Gender: Noun + Adj, run 3\n",
      "--Epoch  0  Loss :  0.5902965664863586\n",
      "--Epoch  10  Loss :  0.38046038150787354\n",
      " Training model:  Gender: Noun, run 4\n",
      "--Epoch  0  Loss :  0.6538946628570557\n",
      "--Epoch  10  Loss :  0.5144742727279663\n",
      " Training model:  Gender: Adj, run 4\n",
      "--Epoch  0  Loss :  0.5796954035758972\n",
      "--Epoch  10  Loss :  0.3872130215167999\n",
      " Training model:  Gender: Noun + Adj, run 4\n",
      "--Epoch  0  Loss :  0.5992268323898315\n",
      "--Epoch  10  Loss :  0.49461835622787476\n",
      " Training model:  Gender: Noun, run 5\n",
      "--Epoch  0  Loss :  0.6675088405609131\n",
      "--Epoch  10  Loss :  0.5277326703071594\n",
      " Training model:  Gender: Adj, run 5\n",
      "--Epoch  0  Loss :  0.6065500974655151\n",
      "--Epoch  10  Loss :  0.43190720677375793\n",
      " Training model:  Gender: Noun + Adj, run 5\n",
      "--Epoch  0  Loss :  0.634282112121582\n",
      "--Epoch  10  Loss :  0.3862055540084839\n",
      " Training model:  Gender: Noun, run 6\n",
      "--Epoch  0  Loss :  0.6370710134506226\n",
      "--Epoch  10  Loss :  0.4921228289604187\n",
      " Training model:  Gender: Adj, run 6\n",
      "--Epoch  0  Loss :  0.6011340618133545\n",
      "--Epoch  10  Loss :  0.5234218835830688\n",
      " Training model:  Gender: Noun + Adj, run 6\n",
      "--Epoch  0  Loss :  0.5525268316268921\n",
      "--Epoch  10  Loss :  0.3996742069721222\n",
      " Training model:  Gender: Noun, run 7\n",
      "--Epoch  0  Loss :  0.6534780263900757\n",
      "--Epoch  10  Loss :  0.4867800772190094\n",
      " Training model:  Gender: Adj, run 7\n",
      "--Epoch  0  Loss :  0.5853701233863831\n",
      "--Epoch  10  Loss :  0.36530911922454834\n",
      " Training model:  Gender: Noun + Adj, run 7\n",
      "--Epoch  0  Loss :  0.5805473327636719\n",
      "--Epoch  10  Loss :  0.40208742022514343\n",
      " Training model:  Gender: Noun, run 8\n",
      "--Epoch  0  Loss :  0.6429083347320557\n",
      "--Epoch  10  Loss :  0.4494304358959198\n",
      " Training model:  Gender: Adj, run 8\n",
      "--Epoch  0  Loss :  0.6991317272186279\n",
      "--Epoch  10  Loss :  0.41462019085884094\n",
      " Training model:  Gender: Noun + Adj, run 8\n",
      "--Epoch  0  Loss :  0.6099328994750977\n",
      "--Epoch  10  Loss :  0.3763348162174225\n",
      " Training model:  Gender: Noun, run 9\n",
      "--Epoch  0  Loss :  0.6296976208686829\n",
      "--Epoch  10  Loss :  0.4873175323009491\n",
      " Training model:  Gender: Adj, run 9\n",
      "--Epoch  0  Loss :  0.6056117415428162\n",
      "--Epoch  10  Loss :  0.3933645486831665\n",
      " Training model:  Gender: Noun + Adj, run 9\n",
      "--Epoch  0  Loss :  0.5966663360595703\n",
      "--Epoch  10  Loss :  0.4108690023422241\n"
     ]
    }
   ],
   "source": [
    "# train the models \n",
    "\n",
    "for y in range(10):\n",
    "    for i in range(3):\n",
    "        print(f\" Training model:  {names[i]}, run {y}\")\n",
    "        \n",
    "        model = nn.Sequential(nn.Linear(512, 2), nn.Softmax(dim=1))\n",
    "        # define the loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        # define the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # put the model in training mode\n",
    "        model.train()\n",
    "        for epoch in range(nb_epochs):\n",
    "            for X_train, Y_train in train_loaders[i]:\n",
    "                # compute the model output\n",
    "                Y_pred = model(X_train)\n",
    "                # calculate loss\n",
    "                loss = loss_fn(Y_pred, Y_train)\n",
    "                # reset the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update model weights\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"--Epoch \", epoch, \" Loss : \", loss.item())\n",
    "        \n",
    "        weights[i].append(model[0].weight.data.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.abs(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender: Noun weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[0][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        noun_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>296</td>\n",
       "      <td>424</td>\n",
       "      <td>410</td>\n",
       "      <td>98</td>\n",
       "      <td>18</td>\n",
       "      <td>218</td>\n",
       "      <td>10</td>\n",
       "      <td>191</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>482</td>\n",
       "      <td>401</td>\n",
       "      <td>463</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>462</td>\n",
       "      <td>143</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>303</td>\n",
       "      <td>467</td>\n",
       "      <td>347</td>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>238</td>\n",
       "      <td>13</td>\n",
       "      <td>239</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>510</td>\n",
       "      <td>381</td>\n",
       "      <td>442</td>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>326</td>\n",
       "      <td>141</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>304</td>\n",
       "      <td>414</td>\n",
       "      <td>478</td>\n",
       "      <td>115</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>461</td>\n",
       "      <td>382</td>\n",
       "      <td>459</td>\n",
       "      <td>6</td>\n",
       "      <td>136</td>\n",
       "      <td>417</td>\n",
       "      <td>92</td>\n",
       "      <td>476</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>272</td>\n",
       "      <td>457</td>\n",
       "      <td>364</td>\n",
       "      <td>136</td>\n",
       "      <td>24</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "      <td>195</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>511</td>\n",
       "      <td>410</td>\n",
       "      <td>476</td>\n",
       "      <td>6</td>\n",
       "      <td>154</td>\n",
       "      <td>446</td>\n",
       "      <td>122</td>\n",
       "      <td>442</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>263</td>\n",
       "      <td>450</td>\n",
       "      <td>378</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>203</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>485</td>\n",
       "      <td>338</td>\n",
       "      <td>436</td>\n",
       "      <td>9</td>\n",
       "      <td>151</td>\n",
       "      <td>356</td>\n",
       "      <td>86</td>\n",
       "      <td>425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "      <td>230</td>\n",
       "      <td>393</td>\n",
       "      <td>420</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>254</td>\n",
       "      <td>10</td>\n",
       "      <td>238</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>442</td>\n",
       "      <td>315</td>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>405</td>\n",
       "      <td>136</td>\n",
       "      <td>497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83</td>\n",
       "      <td>283</td>\n",
       "      <td>428</td>\n",
       "      <td>410</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>193</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>472</td>\n",
       "      <td>366</td>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "      <td>180</td>\n",
       "      <td>447</td>\n",
       "      <td>122</td>\n",
       "      <td>413</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>245</td>\n",
       "      <td>400</td>\n",
       "      <td>457</td>\n",
       "      <td>139</td>\n",
       "      <td>30</td>\n",
       "      <td>264</td>\n",
       "      <td>8</td>\n",
       "      <td>241</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>484</td>\n",
       "      <td>345</td>\n",
       "      <td>510</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>386</td>\n",
       "      <td>129</td>\n",
       "      <td>418</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91</td>\n",
       "      <td>306</td>\n",
       "      <td>360</td>\n",
       "      <td>393</td>\n",
       "      <td>107</td>\n",
       "      <td>22</td>\n",
       "      <td>246</td>\n",
       "      <td>11</td>\n",
       "      <td>179</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>501</td>\n",
       "      <td>416</td>\n",
       "      <td>480</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>409</td>\n",
       "      <td>100</td>\n",
       "      <td>464</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>256</td>\n",
       "      <td>436</td>\n",
       "      <td>392</td>\n",
       "      <td>113</td>\n",
       "      <td>21</td>\n",
       "      <td>311</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>504</td>\n",
       "      <td>362</td>\n",
       "      <td>424</td>\n",
       "      <td>5</td>\n",
       "      <td>161</td>\n",
       "      <td>400</td>\n",
       "      <td>129</td>\n",
       "      <td>484</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4   5    6   7    8    9  ...  503  504  505  506  \\\n",
       "0   70  296  424  410   98  18  218  10  191  148  ...  135  482  401  463   \n",
       "1   66  303  467  347   92  21  238  13  239  142  ...  102  510  381  442   \n",
       "2  100  304  414  478  115  32  256  11  168  177  ...  119  461  382  459   \n",
       "3   87  272  457  364  136  24  261  11  195  129  ...  109  511  410  476   \n",
       "4   66  263  450  378   93  31  262   6  203  169  ...  126  485  338  436   \n",
       "5   61  230  393  420  100  36  254  10  238  178  ...  151  442  315  438   \n",
       "6   83  283  428  410   89  24  251  13  193  176  ...  133  472  366  438   \n",
       "7   72  245  400  457  139  30  264   8  241  122  ...   94  484  345  510   \n",
       "8   91  306  360  393  107  22  246  11  179  140  ...  127  501  416  480   \n",
       "9   60  256  436  392  113  21  311  10  177  164  ...  123  504  362  424   \n",
       "\n",
       "  507  508  509  510  511 run  \n",
       "0   5  195  462  143  446   0  \n",
       "1   6  152  326  141  480   1  \n",
       "2   6  136  417   92  476   2  \n",
       "3   6  154  446  122  442   3  \n",
       "4   9  151  356   86  425   4  \n",
       "5   6  176  405  136  497   5  \n",
       "6   6  180  447  122  413   6  \n",
       "7   4  141  386  129  418   7  \n",
       "8   5  149  409  100  464   8  \n",
       "9   5  161  400  129  484   9  \n",
       "\n",
       "[10 rows x 513 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    0.0\n",
       "434    1.7\n",
       "162    1.9\n",
       "316    3.2\n",
       "377    4.3\n",
       "245    4.9\n",
       "507    5.8\n",
       "250    7.8\n",
       "186    9.1\n",
       "117    9.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender: Adj weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[1][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        adj_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466    0.2\n",
       "250    1.3\n",
       "245    2.2\n",
       "439    3.3\n",
       "5      4.5\n",
       "181    5.9\n",
       "133    6.6\n",
       "177    6.8\n",
       "88     9.5\n",
       "503    9.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender: both weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[2][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        both_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    0.2\n",
       "377    0.9\n",
       "507    3.0\n",
       "245    3.1\n",
       "250    3.4\n",
       "100    5.1\n",
       "316    5.8\n",
       "434    6.5\n",
       "28     8.6\n",
       "499    8.8\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3de7a084b318d7b8bf96005cb5db4da14a27f60df0465391ef48a4c336f03bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
