{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans for PoS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Loading : unique NOUNS, VERBS, ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# WE Loading\n",
    "all_n_we = pd.read_csv('../Data/FlauBERT_WE/all_nouns_we.csv', index_col=0).drop(columns=[\"number\", \"gender\"])\n",
    "all_a_we = pd.read_csv('../Data/FlauBERT_WE/all_adjectives_we.csv', index_col=0).drop(columns = [\"number\", \"gender\"])\n",
    "all_v_we = pd.read_csv('../Data/FlauBERT_WE/all_verb_we.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NOUN vs not-NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# label 1: NOUN, 0: not NOUN\n",
    "all_n_we[\"noun\"] = 1\n",
    "all_av_we = pd.concat([all_a_we, all_v_we, all_n_we])\n",
    "all_av_we[\"noun\"] = 0\n",
    "\n",
    "# Normalization and concatenation\n",
    "df = pd.concat([all_av_we, all_n_we])\n",
    "norm_df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# Removing words having multiple POS\n",
    "word, count = np.unique(norm_df.index, return_counts=True)\n",
    "unique_words = [x[0] for x in list(filter(lambda x: x[1] == 1, zip(word, count)))]\n",
    "un_nouns =  norm_df[norm_df.index.isin(unique_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5483\n",
       "Name: noun, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_nouns[\"noun\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_list_1= [str(i) for i in range(512)] # all dimensions\n",
    "df_clustering_1 = pd.DataFrame(columns = [\"ARI\"])\n",
    "ari = []\n",
    "\n",
    "for dim in dim_list_1:\n",
    "\n",
    "    # Clustering using Kmeans\n",
    "    km = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    km.fit(norm_df[dim].values.reshape(-1, 1))\n",
    "\n",
    "    # Compute the Adjusted Rand Index: the closer to 1, the better\n",
    "    ari.append(adjusted_rand_score(norm_df[\"noun\"], km.labels_))\n",
    "\n",
    "df_clustering_1[\"ARI\"] = ari\n",
    "df_clustering_1.index = dim_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ARI\n",
       "0    0.0\n",
       "1    0.0\n",
       "350  0.0\n",
       "349  0.0\n",
       "348  0.0\n",
       "347  0.0\n",
       "346  0.0\n",
       "345  0.0\n",
       "344  0.0\n",
       "343  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_1 = df_clustering_1.sort_values(by = \"ARI\", ascending = False)\n",
    "dim_top10_1 = list(top10_1.head(10).index)\n",
    "top10_1.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3de7a084b318d7b8bf96005cb5db4da14a27f60df0465391ef48a4c336f03bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
