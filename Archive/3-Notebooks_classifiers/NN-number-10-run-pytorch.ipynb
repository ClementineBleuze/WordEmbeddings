{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data: NOUN, ADJ, and both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nouns_we = pd.read_csv('../Data/FlauBERT_WE/all_nouns_we.csv').drop(columns=[\"gender\"])\n",
    "df_adj_we = pd.read_csv('../Data/FlauBERT_WE/all_adjectives_we.csv').drop(columns = \"gender\")\n",
    "df_both_we = pd.concat([df_nouns_we, df_adj_we], ignore_index=True)\n",
    "# target : number\n",
    "Y_nb_N = df_nouns_we[\"number\"].apply(lambda x: 1 if x == \"singular\" else 0)\n",
    "Y_nb_A = df_adj_we[\"number\"].apply(lambda x: 1 if x == \"singular\" else 0)\n",
    "Y_nb_both = df_both_we[\"number\"].apply(lambda x: 1 if x == \"singular\" else 0)\n",
    "# features : word embeddings dimensions\n",
    "X_nb_N = df_nouns_we.drop(columns=[\"Word\", \"number\"])\n",
    "X_nb_A = df_adj_we.drop(columns=[\"Word\", \"number\"])\n",
    "X_nb_both = df_both_we.drop(columns = [\"Word\", \"number\"] )\n",
    "\n",
    "# normalize data to be between 0 and 1\n",
    "X_nb_N = (X_nb_N - X_nb_N.min()) / (X_nb_N.max() - X_nb_N.min())\n",
    "X_nb_A = (X_nb_A - X_nb_A.min()) / (X_nb_A.max() - X_nb_A.min())\n",
    "X_nb_both = (X_nb_both - X_nb_both.min()) / (X_nb_both.max() - X_nb_both.min())\n",
    "\n",
    "\n",
    "# split data into train and test sets\n",
    "X_nb_N_train, X_nb_N_test, Y_nb_N_train, Y_nb_N_test = train_test_split(X_nb_N, Y_nb_N, test_size=0.2, random_state=42)\n",
    "X_nb_A_train, X_nb_A_test, Y_nb_A_train, Y_nb_A_test = train_test_split(X_nb_A, Y_nb_A, test_size=0.2, random_state=42)\n",
    "X_nb_both_train, X_nb_both_test, Y_nb_both_train, Y_nb_both_test = train_test_split(X_nb_both, Y_nb_both, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = [X_nb_N_train, X_nb_A_train, X_nb_both_train]\n",
    "test_feature = [X_nb_N_test, X_nb_A_test, X_nb_both_test]\n",
    "train_target = [Y_nb_N_train, Y_nb_A_train, Y_nb_both_train]\n",
    "test_target = [Y_nb_N_test, Y_nb_A_test, Y_nb_both_test]\n",
    "\n",
    "names = ['Number: Noun', 'Number: Adjs', 'Number: Both']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "train_feature = [torch.tensor(x.values).float() for x in train_feature]\n",
    "test_feature = [torch.tensor(x.values).float() for x in test_feature]\n",
    "train_target = [torch.tensor(x.values).long() for x in train_target]\n",
    "test_target = [torch.tensor(x.values).long() for x in test_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# the TensorDataset is a ready to use class to represent your data as list of tensors. \n",
    "# Note that input_features and labels must match on the length of the first dimension\n",
    "train_sets = [TensorDataset(X_train, Y_train) for X_train, Y_train in zip(train_feature, train_target)]\n",
    "test_sets = [TensorDataset(X_valid, Y_valid) for X_valid, Y_valid in zip(test_feature, test_target)]\n",
    "\n",
    "# DataLoader shuffles and batches the data and load its in parallel using multiprocessing workers\n",
    "train_loaders = [DataLoader(train_set, batch_size=32, shuffle=True) for train_set in train_sets]\n",
    "test_loaders = [DataLoader(test_set, batch_size=32) for test_set in test_sets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [[], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training model:  Number: Noun, run 0\n",
      "--Epoch  0  Loss :  0.5339772701263428\n",
      "--Epoch  10  Loss :  0.3435690701007843\n",
      " Training model:  Number: Adjs, run 0\n",
      "--Epoch  0  Loss :  0.6323344111442566\n",
      "--Epoch  10  Loss :  0.35955438017845154\n",
      " Training model:  Number: Both, run 0\n",
      "--Epoch  0  Loss :  0.5656259655952454\n",
      "--Epoch  10  Loss :  0.3276616632938385\n",
      " Training model:  Number: Noun, run 1\n",
      "--Epoch  0  Loss :  0.5480201840400696\n",
      "--Epoch  10  Loss :  0.35430285334587097\n",
      " Training model:  Number: Adjs, run 1\n",
      "--Epoch  0  Loss :  0.6420716643333435\n",
      "--Epoch  10  Loss :  0.37520483136177063\n",
      " Training model:  Number: Both, run 1\n",
      "--Epoch  0  Loss :  0.6836819052696228\n",
      "--Epoch  10  Loss :  0.3508302867412567\n",
      " Training model:  Number: Noun, run 2\n",
      "--Epoch  0  Loss :  0.5583521127700806\n",
      "--Epoch  10  Loss :  0.38170331716537476\n",
      " Training model:  Number: Adjs, run 2\n",
      "--Epoch  0  Loss :  0.5966718792915344\n",
      "--Epoch  10  Loss :  0.3695962131023407\n",
      " Training model:  Number: Both, run 2\n",
      "--Epoch  0  Loss :  0.5465124249458313\n",
      "--Epoch  10  Loss :  0.32893112301826477\n",
      " Training model:  Number: Noun, run 3\n",
      "--Epoch  0  Loss :  0.5751935839653015\n",
      "--Epoch  10  Loss :  0.3934526741504669\n",
      " Training model:  Number: Adjs, run 3\n",
      "--Epoch  0  Loss :  0.5958230495452881\n",
      "--Epoch  10  Loss :  0.42195263504981995\n",
      " Training model:  Number: Both, run 3\n",
      "--Epoch  0  Loss :  0.6093443632125854\n",
      "--Epoch  10  Loss :  0.3270179331302643\n",
      " Training model:  Number: Noun, run 4\n",
      "--Epoch  0  Loss :  0.5781543254852295\n",
      "--Epoch  10  Loss :  0.35466936230659485\n",
      " Training model:  Number: Adjs, run 4\n",
      "--Epoch  0  Loss :  0.6029714941978455\n",
      "--Epoch  10  Loss :  0.42655104398727417\n",
      " Training model:  Number: Both, run 4\n",
      "--Epoch  0  Loss :  0.5319894552230835\n",
      "--Epoch  10  Loss :  0.3247339427471161\n",
      " Training model:  Number: Noun, run 5\n",
      "--Epoch  0  Loss :  0.5388489365577698\n",
      "--Epoch  10  Loss :  0.3955293893814087\n",
      " Training model:  Number: Adjs, run 5\n",
      "--Epoch  0  Loss :  0.6060453057289124\n",
      "--Epoch  10  Loss :  0.40474042296409607\n",
      " Training model:  Number: Both, run 5\n",
      "--Epoch  0  Loss :  0.5520179271697998\n",
      "--Epoch  10  Loss :  0.33467531204223633\n",
      " Training model:  Number: Noun, run 6\n",
      "--Epoch  0  Loss :  0.601459801197052\n",
      "--Epoch  10  Loss :  0.35046911239624023\n",
      " Training model:  Number: Adjs, run 6\n",
      "--Epoch  0  Loss :  0.5414342284202576\n",
      "--Epoch  10  Loss :  0.392938494682312\n",
      " Training model:  Number: Both, run 6\n",
      "--Epoch  0  Loss :  0.5946194529533386\n",
      "--Epoch  10  Loss :  0.37088891863822937\n",
      " Training model:  Number: Noun, run 7\n",
      "--Epoch  0  Loss :  0.5327560305595398\n",
      "--Epoch  10  Loss :  0.35578298568725586\n",
      " Training model:  Number: Adjs, run 7\n",
      "--Epoch  0  Loss :  0.5761398673057556\n",
      "--Epoch  10  Loss :  0.37461337447166443\n",
      " Training model:  Number: Both, run 7\n",
      "--Epoch  0  Loss :  0.5721492171287537\n",
      "--Epoch  10  Loss :  0.344701886177063\n",
      " Training model:  Number: Noun, run 8\n",
      "--Epoch  0  Loss :  0.5416790843009949\n",
      "--Epoch  10  Loss :  0.3489137291908264\n",
      " Training model:  Number: Adjs, run 8\n",
      "--Epoch  0  Loss :  0.6548070311546326\n",
      "--Epoch  10  Loss :  0.379184365272522\n",
      " Training model:  Number: Both, run 8\n",
      "--Epoch  0  Loss :  0.5546350479125977\n",
      "--Epoch  10  Loss :  0.34257230162620544\n",
      " Training model:  Number: Noun, run 9\n",
      "--Epoch  0  Loss :  0.5726543068885803\n",
      "--Epoch  10  Loss :  0.3825297951698303\n",
      " Training model:  Number: Adjs, run 9\n",
      "--Epoch  0  Loss :  0.5473660826683044\n",
      "--Epoch  10  Loss :  0.39497435092926025\n",
      " Training model:  Number: Both, run 9\n",
      "--Epoch  0  Loss :  0.5035380125045776\n",
      "--Epoch  10  Loss :  0.33020710945129395\n"
     ]
    }
   ],
   "source": [
    "# train the models \n",
    "\n",
    "for y in range(10):\n",
    "    for i in range(3):\n",
    "        print(f\" Training model:  {names[i]}, run {y}\")\n",
    "        \n",
    "        model = nn.Sequential(nn.Linear(512, 2), nn.Softmax(dim=1))\n",
    "        # define the loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        # define the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # put the model in training mode\n",
    "        model.train()\n",
    "        for epoch in range(nb_epochs):\n",
    "            for X_train, Y_train in train_loaders[i]:\n",
    "                # compute the model output\n",
    "                Y_pred = model(X_train)\n",
    "                # calculate loss\n",
    "                loss = loss_fn(Y_pred, Y_train)\n",
    "                # reset the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update model weights\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"--Epoch \", epoch, \" Loss : \", loss.item())\n",
    "        \n",
    "        weights[i].append(model[0].weight.data.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.abs(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number: Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[0][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        noun_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310     0.0\n",
       "54      1.0\n",
       "158     2.0\n",
       "285     3.0\n",
       "359     4.6\n",
       "172     5.3\n",
       "384     5.9\n",
       "495     6.3\n",
       "250     8.8\n",
       "182    10.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = list(pd.read_csv('../Data/Dimensions/GN/noun.csv', index_col=0).iloc[:, 0].values)\n",
    "\n",
    "w1.extend(noun_weights.iloc[:, :512].mean().sort_values()[:10].index)\n",
    "\n",
    "pd.DataFrame(w1).to_csv('../Data/Dimensions/GN/noun.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number: Adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[1][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        adj_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310    0.0\n",
       "285    1.3\n",
       "54     1.7\n",
       "384    3.9\n",
       "455    5.0\n",
       "495    6.6\n",
       "200    7.6\n",
       "360    8.2\n",
       "192    8.7\n",
       "25     9.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = list(pd.read_csv('../Data/Dimensions/GN/adj.csv', index_col=0).iloc[:, 0].values)\n",
    "\n",
    "w1.extend(adj_weights.iloc[:, :512].mean().sort_values()[:10].index)\n",
    "\n",
    "pd.DataFrame(w1).to_csv('../Data/Dimensions/GN/adj.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number: both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_weights = pd.DataFrame(columns=list(range(512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_weights['run'] = list(range(10))\n",
    "for r in range(10):\n",
    "    dims_sorted = [x[0] for x in sorted(enumerate(weights[2][r]), key=lambda x: abs(x[1]), reverse=True)]\n",
    "    for i in range(len(dims_sorted)):\n",
    "        both_weights.iloc[r, dims_sorted[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310    0.0\n",
       "54     1.0\n",
       "158    2.0\n",
       "285    3.0\n",
       "359    4.1\n",
       "384    5.1\n",
       "172    6.4\n",
       "495    6.7\n",
       "250    8.5\n",
       "200    9.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_weights.iloc[:, :512].mean().sort_values()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = list(pd.read_csv('../Data/Dimensions/GN/both.csv', index_col=0).iloc[:, 0].values)\n",
    "\n",
    "w1.extend(both_weights.iloc[:, :512].mean().sort_values()[:10].index)\n",
    "\n",
    "pd.DataFrame(w1).to_csv('../Data/Dimensions/GN/both.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3de7a084b318d7b8bf96005cb5db4da14a27f60df0465391ef48a4c336f03bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
