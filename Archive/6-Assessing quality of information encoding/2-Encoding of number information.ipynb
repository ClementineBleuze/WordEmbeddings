{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac006e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f48d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import aabcc, sig_props, correlation, lr, perceptron, kmeans_1dim, \\\n",
    "                     score_comparison, run_tests, report, dimensions_report, repeated_dimensions, \\\n",
    "                    kmeans_multi_dim\n",
    "from preparation import prepare_dataset, read_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd6ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e895408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b537ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f26bf",
   "metadata": {},
   "source": [
    "Due to big size of WE files they are not uploaded to Github, but can instead be downloaded [here](https://drive.google.com/drive/folders/10Ea62GRlq4t7bq-nK9tPtYFu0kbCciey?usp=sharing).\n",
    "\n",
    "The code below expects a folder \"Data\" in the root folder containing all the information from the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8faf03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert/camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'xlm-roberta-large',\n",
    "        'label': 'xlm_large'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'xlm-roberta-base', \n",
    "        'label': 'xlm_base'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-uncased',\n",
    "        'label': 'bert_base_u'\n",
    "    },\n",
    "    {\n",
    "        'name': 'distilbert-base-multilingual-cased',\n",
    "        'label': 'distilbert_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-cased',\n",
    "        'label': 'bert_base_c'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [m['label'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba233d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_with_features = read_datasets(\n",
    "                            path = '../Data',\n",
    "                            model_labels = labels,\n",
    "                            file_name = 'all_unique_pos_we.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091c3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>Number</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D</th>\n",
       "      <td>5.531172</td>\n",
       "      <td>-8.963815</td>\n",
       "      <td>1.558320</td>\n",
       "      <td>3.143550</td>\n",
       "      <td>-5.372142</td>\n",
       "      <td>-0.174002</td>\n",
       "      <td>-1.124767</td>\n",
       "      <td>5.729996</td>\n",
       "      <td>-2.367389</td>\n",
       "      <td>4.247167</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.374313</td>\n",
       "      <td>-7.161043</td>\n",
       "      <td>2.704918</td>\n",
       "      <td>-4.613951</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>2D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>3.969331</td>\n",
       "      <td>-6.442656</td>\n",
       "      <td>1.451928</td>\n",
       "      <td>3.447791</td>\n",
       "      <td>-4.224664</td>\n",
       "      <td>-1.029557</td>\n",
       "      <td>-3.664733</td>\n",
       "      <td>4.911453</td>\n",
       "      <td>0.223902</td>\n",
       "      <td>5.621365</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.463473</td>\n",
       "      <td>-10.008975</td>\n",
       "      <td>2.005870</td>\n",
       "      <td>-2.951385</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>3D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>5.617864</td>\n",
       "      <td>-6.741737</td>\n",
       "      <td>2.519838</td>\n",
       "      <td>-3.914263</td>\n",
       "      <td>2.801907</td>\n",
       "      <td>-1.182259</td>\n",
       "      <td>4.435670</td>\n",
       "      <td>-1.600746</td>\n",
       "      <td>-0.582458</td>\n",
       "      <td>1.409745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108588</td>\n",
       "      <td>0.809533</td>\n",
       "      <td>-10.274058</td>\n",
       "      <td>2.984729</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aba</th>\n",
       "      <td>4.914313</td>\n",
       "      <td>-6.923126</td>\n",
       "      <td>-3.848757</td>\n",
       "      <td>5.110574</td>\n",
       "      <td>-2.516107</td>\n",
       "      <td>-4.938292</td>\n",
       "      <td>2.373581</td>\n",
       "      <td>-2.756590</td>\n",
       "      <td>2.567556</td>\n",
       "      <td>2.412183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979258</td>\n",
       "      <td>-2.605051</td>\n",
       "      <td>-7.204095</td>\n",
       "      <td>-4.154819</td>\n",
       "      <td>singular</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aba</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaisse</th>\n",
       "      <td>4.652038</td>\n",
       "      <td>-4.028066</td>\n",
       "      <td>0.883200</td>\n",
       "      <td>4.782077</td>\n",
       "      <td>-2.294614</td>\n",
       "      <td>-3.894452</td>\n",
       "      <td>-0.810279</td>\n",
       "      <td>-0.713935</td>\n",
       "      <td>4.819910</td>\n",
       "      <td>4.090150</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.542219</td>\n",
       "      <td>-4.662947</td>\n",
       "      <td>-0.546076</td>\n",
       "      <td>-1.836028</td>\n",
       "      <td>singular</td>\n",
       "      <td>feminine</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "Word                                                                            \n",
       "2D       5.531172 -8.963815  1.558320  3.143550 -5.372142 -0.174002 -1.124767   \n",
       "3D       3.969331 -6.442656  1.451928  3.447791 -4.224664 -1.029557 -3.664733   \n",
       "aa       5.617864 -6.741737  2.519838 -3.914263  2.801907 -1.182259  4.435670   \n",
       "aba      4.914313 -6.923126 -3.848757  5.110574 -2.516107 -4.938292  2.373581   \n",
       "abaisse  4.652038 -4.028066  0.883200  4.782077 -2.294614 -3.894452 -0.810279   \n",
       "\n",
       "                7         8         9  ...       508        509        510  \\\n",
       "Word                                   ...                                   \n",
       "2D       5.729996 -2.367389  4.247167  ... -2.374313  -7.161043   2.704918   \n",
       "3D       4.911453  0.223902  5.621365  ... -1.463473 -10.008975   2.005870   \n",
       "aa      -1.600746 -0.582458  1.409745  ... -0.108588   0.809533 -10.274058   \n",
       "aba     -2.756590  2.567556  2.412183  ... -0.979258  -2.605051  -7.204095   \n",
       "abaisse -0.713935  4.819910  4.090150  ... -7.542219  -4.662947  -0.546076   \n",
       "\n",
       "              511      Number     Gender    Lemma   POS  Tense  Person  \n",
       "Word                                                                    \n",
       "2D      -4.613951  invariable   feminine       2D  NOUN    NaN     NaN  \n",
       "3D      -2.951385  invariable   feminine       3D  NOUN    NaN     NaN  \n",
       "aa       2.984729  invariable  masculine       aa  NOUN    NaN     NaN  \n",
       "aba     -4.154819    singular  masculine      aba  NOUN    NaN     NaN  \n",
       "abaisse -1.836028    singular   feminine  abaisse  NOUN    NaN     NaN  \n",
       "\n",
       "[5 rows x 518 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_with_features[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 6 extra feautres in addition to embedding dimensions in the file: number, gender, lemma, pos, tense,\n",
    "# person\n",
    "feature_col_count = 6\n",
    "\n",
    "# Feature to investigate in this notebook\n",
    "feature = 'Number'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da06780",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d134",
   "metadata": {},
   "source": [
    "1. Exclude datapoints with undefined feature values (e.g. Gender = `invariable`)\n",
    "2. Encode a grammatical feature as binary (e.g. Gender = 0 if masculine and 1 if feminine) (feature vector)\n",
    "3. Shuffle the data set\n",
    "4. Separate the dataset into 80% \"training\" and 20% test data\n",
    "5. For each dimension in the test dataset measure if the dimension values are dependent on the grammatic feature\n",
    "* Using [ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html): The data is split into 2 samples, all dimension values when the grammatical feature is 0 and when it's equal to 1.\n",
    "* Using [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "6. For each dimension highlighted during step #5 find medians for 2 subgroups: when the grammatical feature == 0 and when it == 1.\n",
    "7. For each word in the test dataset, find the predicted label using MSE using medians of the dimensions from #6.\n",
    "8. Compute accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bbb6b",
   "metadata": {},
   "source": [
    "We assume that achieved accuracies can be an efficient way of comparing the quality of grammatical information encoding in the word embeddings.\n",
    "\n",
    "The experiments for `Gender` and `Number` will be performed for \"nouns only\", \"adjectives only\" and \"nouns and adjectives\" combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a760",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bc1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the experiment with nouns only\n",
    "pos = ['NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07b0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noun_train = []\n",
    "y_noun_train = []\n",
    "\n",
    "X_noun_test = []\n",
    "y_noun_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70563c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Number != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_noun_train.append(xtr)\n",
    "    X_noun_test.append(xtst)\n",
    "    \n",
    "    y_noun_train.append(ytr)\n",
    "    y_noun_test.append(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ddfb0",
   "metadata": {},
   "source": [
    "### Compute ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eed918",
   "metadata": {},
   "source": [
    "We split each dimension into 2 samples: feminine nouns and masculine nouns. ANOVA test is used to assess if the population means are the same.\n",
    "\n",
    "If the population means are not the same, we can make an assumption that the gender information affects the distribution of values in the given dimension.\n",
    "\n",
    "If p-value < 0.001, reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3596e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73edb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2cc630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_noun_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims.append(model_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5b5d3",
   "metadata": {},
   "source": [
    "We can see that a very large amount of dimensions appear to be highlighted by the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d86239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "Total dimensions 512\n",
      "ANOVA dimensions: 389\n",
      "\n",
      "flau_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 347\n",
      "\n",
      "flau_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 495\n",
      "\n",
      "flau_large_c:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 860\n",
      "\n",
      "cam_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 15\n",
      "\n",
      "xlm_large:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 255\n",
      "\n",
      "xlm_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 131\n",
      "\n",
      "bert_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 634\n",
      "\n",
      "distilbert_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 329\n",
      "\n",
      "bert_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}:\\nTotal dimensions {len(X_noun_train[i].columns)}\\nANOVA dimensions: {len(anova_dims[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867da94",
   "metadata": {},
   "source": [
    "### Compute Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488513e3",
   "metadata": {},
   "source": [
    "If mutual information is 0, we can consider that a given dimension is independent from Number information.\n",
    "\n",
    "If MI > 0, we can't consider the dimension completely independent and it could encode the Number information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad7be602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_noun_train[i], y_noun_train[i], discrete_features=[False]*len(X_noun_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a327f1f",
   "metadata": {},
   "source": [
    "Overall, threshold of 0 finds much more dimensions. This could be potentially addressed with a different threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b05902a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "    Total dimensions 512\n",
      "    ANOVA dimensions: 389\n",
      "    Mutual Information dimension: 382\n",
      "\n",
      "\n",
      "flau_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 347\n",
      "    Mutual Information dimension: 474\n",
      "\n",
      "\n",
      "flau_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 495\n",
      "    Mutual Information dimension: 531\n",
      "\n",
      "\n",
      "flau_large_c:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 860\n",
      "    Mutual Information dimension: 798\n",
      "\n",
      "\n",
      "cam_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 15\n",
      "    Mutual Information dimension: 385\n",
      "\n",
      "\n",
      "xlm_large:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 255\n",
      "    Mutual Information dimension: 626\n",
      "\n",
      "\n",
      "xlm_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 131\n",
      "    Mutual Information dimension: 393\n",
      "\n",
      "\n",
      "bert_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 634\n",
      "    Mutual Information dimension: 723\n",
      "\n",
      "\n",
      "distilbert_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 329\n",
      "    Mutual Information dimension: 541\n",
      "\n",
      "\n",
      "bert_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 0\n",
      "    Mutual Information dimension: 506\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f\"\"\"{models[i]['label']}:\n",
    "    Total dimensions {len(X_noun_train[i].columns)}\n",
    "    ANOVA dimensions: {len(anova_dims[i])}\n",
    "    Mutual Information dimension: {len(mi_dims[i])}\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af43dc",
   "metadata": {},
   "source": [
    "For now, for each model we select only dimensions that are potentially dependent on the gender information and found by the both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d64f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims = [set(anova_dims[i]).intersection(mi_dims[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a713",
   "metadata": {},
   "source": [
    "Final number of dimensions that we can consider not independent from the gender information for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dae8ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 303\n",
      "flau_base_u: 170\n",
      "flau_base_c: 340\n",
      "flau_large_c: 695\n",
      "cam_base: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42aabdc",
   "metadata": {},
   "source": [
    "Note that for FlauBERT large the number of highlighted dimensions is more than half of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666804dc",
   "metadata": {},
   "source": [
    "### Compute medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07503183",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_mi = []\n",
    "medians_annova = []\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cfc73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(mi_annova_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(mi_annova_dims[i])].median()\n",
    "    medians.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d276c5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_0</th>\n",
       "      <th>median_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.456081</td>\n",
       "      <td>0.465711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.493716</td>\n",
       "      <td>0.487428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.489034</td>\n",
       "      <td>0.472311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.548405</td>\n",
       "      <td>0.532761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.561518</td>\n",
       "      <td>0.548537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.552575</td>\n",
       "      <td>0.536434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.526278</td>\n",
       "      <td>0.508561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.489403</td>\n",
       "      <td>0.493247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.490570</td>\n",
       "      <td>0.494852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.464360</td>\n",
       "      <td>0.454427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     median_0  median_1\n",
       "151  0.456081  0.465711\n",
       "193  0.493716  0.487428\n",
       "247  0.489034  0.472311\n",
       "275  0.548405  0.532761\n",
       "276  0.561518  0.548537\n",
       "..        ...       ...\n",
       "97   0.552575  0.536434\n",
       "637  0.526278  0.508561\n",
       "700  0.489403  0.493247\n",
       "535  0.490570  0.494852\n",
       "239  0.464360  0.454427\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe5f06",
   "metadata": {},
   "source": [
    "### Predict label for test set using MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ae32713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4749af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44bc8",
   "metadata": {},
   "source": [
    "### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a5128ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.9165680473372781\n",
      "flau_base_u: Accuracy 0.6323040380047505\n",
      "flau_base_c: Accuracy 0.6408284023668639\n",
      "flau_large_c: Accuracy 0.936094674556213\n",
      "cam_base: Accuracy 0.5414462081128748\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_noun_test[i], y_preds[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304fd3f",
   "metadata": {},
   "source": [
    "# Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fd2f3",
   "metadata": {},
   "source": [
    "Repeat all steps but for adjectives only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a9c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d031f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adj_train = []\n",
    "y_adj_train = []\n",
    "\n",
    "X_adj_test = []\n",
    "y_adj_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f3d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_adj_train.append(xtr)\n",
    "    X_adj_test.append(xtst)\n",
    "    \n",
    "    y_adj_train.append(ytr)\n",
    "    y_adj_test.append(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00d5a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2835afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_adj_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_adj.append(model_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6290e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b8ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_adj_train[i], y_adj_train[i], discrete_features=[False]*len(X_adj_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_adj.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1c839f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims_adj = [set(anova_dims_adj[i]).intersection(mi_dims_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d56f9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecc2ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_adj.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c439ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac68a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_adj.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c92fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91257f",
   "metadata": {},
   "source": [
    "Here are the accuracies for adjectives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dfeb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.40816326530612246\n",
      "flau_base_u: Accuracy 0.2890792291220557\n",
      "flau_base_c: Accuracy 0.288265306122449\n",
      "flau_large_c: Accuracy 0.4107142857142857\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/multiclass.py:167\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:795\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 795\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_adj_test[i], y_preds_adj[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/multiclass.py:311\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/multiclass.py:174\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;66;03m# dtype=object should be provided explicitly for ragged arrays,\u001b[39;00m\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;66;03m# see NEP 34\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m             y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:795\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    791\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    792\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    793\u001b[0m )\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 795\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_adj_test[i], y_preds_adj[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8bff8",
   "metadata": {},
   "source": [
    "# Adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d932b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.29818857408267535\n",
      "flau_base_u: Accuracy 0.23401869158878505\n",
      "flau_base_c: Accuracy 0.215513237343242\n",
      "flau_large_c: Accuracy 0.3111936832326986\n",
      "cam_base: Accuracy 0.10642857142857143\n"
     ]
    }
   ],
   "source": [
    "pos = ['ADJ', 'NOUN']\n",
    "\n",
    "X_na_train = []\n",
    "y_na_train = []\n",
    "\n",
    "X_na_test = []\n",
    "y_na_test = []\n",
    "\n",
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_na_train.append(xtr)\n",
    "    X_na_test.append(xtst)\n",
    "    \n",
    "    y_na_train.append(ytr)\n",
    "    y_na_test.append(ytst)\n",
    "\n",
    "anova_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_na_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_na.append(model_dims)\n",
    "\n",
    "mi_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_na_train[i], y_na_train[i], discrete_features=[False]*len(X_na_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_na.append(non_indep_dims)\n",
    "\n",
    "mi_annova_dims_na = [set(anova_dims_na[i]).intersection(mi_dims_na[i]) for i in range(len(models))]\n",
    "\n",
    "medians_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0][list(mi_annova_dims_na[i])].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1][list(mi_annova_dims_na[i])].median()\n",
    "    medians_na.append(medians_df)\n",
    "\n",
    "y_preds_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mse0 = X_na_test[i][list(mi_annova_dims_na[i])].apply(lambda x: mean_absolute_error(medians_na[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_na_test[i][list(mi_annova_dims_na[i])].apply(lambda x: mean_absolute_error(medians_na[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_na.append(y_pred)\n",
    "\n",
    "accs_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_na_test[i], y_preds_na[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330f3fa",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54cc57",
   "metadata": {},
   "source": [
    "We can see that the accuracy is much higher for classifying nouns than adjectives.\n",
    "\n",
    "For some reason, the accuracy for predictions on adjectives is below random choice.\n",
    "\n",
    "Once again FlauBERT small despite much smaller size is showing comparable accuracy with FlauBERT large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773ccae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
