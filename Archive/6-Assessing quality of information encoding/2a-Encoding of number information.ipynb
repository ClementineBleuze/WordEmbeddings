{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac006e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f48d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import aabcc, sig_props, correlation, lr, perceptron, kmeans_1dim, \\\n",
    "                     score_comparison, run_tests, report, dimensions_report, repeated_dimensions, \\\n",
    "                    kmeans_multi_dim\n",
    "from preparation import prepare_dataset, read_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd6ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e895408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b537ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b74df3",
   "metadata": {},
   "source": [
    "Due to big size of WE files they are not uploaded to Github, but can instead be downloaded [here](https://drive.google.com/drive/folders/10Ea62GRlq4t7bq-nK9tPtYFu0kbCciey?usp=sharing).\n",
    "\n",
    "The code below expects a folder \"Data\" in the root folder containing all the information from the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8faf03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert/camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'xlm-roberta-large',\n",
    "        'label': 'xlm_large'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'xlm-roberta-base', \n",
    "        'label': 'xlm_base'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-uncased',\n",
    "        'label': 'bert_base_u'\n",
    "    },\n",
    "    {\n",
    "        'name': 'distilbert-base-multilingual-cased',\n",
    "        'label': 'distilbert_base'\n",
    "    },\n",
    "    {\n",
    "        'name': 'bert-base-multilingual-cased',\n",
    "        'label': 'bert_base_c'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [m['label'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba233d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_with_features = read_datasets(\n",
    "                            path = '../Data',\n",
    "                            model_labels = labels,\n",
    "                            file_name = 'all_unique_pos_we.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091c3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Number</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D</th>\n",
       "      <td>0.370462</td>\n",
       "      <td>-0.543173</td>\n",
       "      <td>0.313777</td>\n",
       "      <td>0.114062</td>\n",
       "      <td>0.105755</td>\n",
       "      <td>0.101263</td>\n",
       "      <td>0.047496</td>\n",
       "      <td>0.941036</td>\n",
       "      <td>-0.635094</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262812</td>\n",
       "      <td>-0.034462</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>-0.339070</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>2D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>0.354640</td>\n",
       "      <td>-0.545033</td>\n",
       "      <td>0.300138</td>\n",
       "      <td>0.125182</td>\n",
       "      <td>0.109215</td>\n",
       "      <td>0.103105</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>0.945384</td>\n",
       "      <td>-0.627031</td>\n",
       "      <td>0.362873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266173</td>\n",
       "      <td>-0.040272</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>-0.345399</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>3D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.350173</td>\n",
       "      <td>-0.535272</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>0.116959</td>\n",
       "      <td>0.096526</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>-0.610729</td>\n",
       "      <td>0.365452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266548</td>\n",
       "      <td>-0.035119</td>\n",
       "      <td>-0.017618</td>\n",
       "      <td>-0.364172</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.348776</td>\n",
       "      <td>-0.534598</td>\n",
       "      <td>0.285159</td>\n",
       "      <td>0.137568</td>\n",
       "      <td>0.115843</td>\n",
       "      <td>0.096030</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>0.942982</td>\n",
       "      <td>-0.611038</td>\n",
       "      <td>0.366652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>-0.034558</td>\n",
       "      <td>-0.017089</td>\n",
       "      <td>-0.363497</td>\n",
       "      <td>singular</td>\n",
       "      <td>masculine</td>\n",
       "      <td>abandon</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbaye</th>\n",
       "      <td>0.342727</td>\n",
       "      <td>-0.537595</td>\n",
       "      <td>0.289408</td>\n",
       "      <td>0.128580</td>\n",
       "      <td>0.121620</td>\n",
       "      <td>0.101963</td>\n",
       "      <td>0.029359</td>\n",
       "      <td>0.952322</td>\n",
       "      <td>-0.611914</td>\n",
       "      <td>0.365287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274898</td>\n",
       "      <td>-0.035381</td>\n",
       "      <td>-0.019363</td>\n",
       "      <td>-0.353987</td>\n",
       "      <td>singular</td>\n",
       "      <td>feminine</td>\n",
       "      <td>abbaye</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "Word                                                                            \n",
       "2D       0.370462 -0.543173  0.313777  0.114062  0.105755  0.101263  0.047496   \n",
       "3D       0.354640 -0.545033  0.300138  0.125182  0.109215  0.103105  0.037388   \n",
       "aa       0.350173 -0.535272  0.285707  0.138325  0.116959  0.096526  0.028733   \n",
       "abandon  0.348776 -0.534598  0.285159  0.137568  0.115843  0.096030  0.028422   \n",
       "abbaye   0.342727 -0.537595  0.289408  0.128580  0.121620  0.101963  0.029359   \n",
       "\n",
       "                7         8         9  ...       764       765       766  \\\n",
       "Word                                   ...                                 \n",
       "2D       0.941036 -0.635094  0.351250  ...  0.262812 -0.034462  0.003319   \n",
       "3D       0.945384 -0.627031  0.362873  ...  0.266173 -0.040272 -0.011564   \n",
       "aa       0.941748 -0.610729  0.365452  ...  0.266548 -0.035119 -0.017618   \n",
       "abandon  0.942982 -0.611038  0.366652  ...  0.266958 -0.034558 -0.017089   \n",
       "abbaye   0.952322 -0.611914  0.365287  ...  0.274898 -0.035381 -0.019363   \n",
       "\n",
       "              767      Number     Gender    Lemma   POS  Tense  Person  \n",
       "Word                                                                    \n",
       "2D      -0.339070  invariable   feminine       2D  NOUN    NaN     NaN  \n",
       "3D      -0.345399  invariable   feminine       3D  NOUN    NaN     NaN  \n",
       "aa      -0.364172  invariable  masculine       aa  NOUN    NaN     NaN  \n",
       "abandon -0.363497    singular  masculine  abandon  NOUN    NaN     NaN  \n",
       "abbaye  -0.353987    singular   feminine   abbaye  NOUN    NaN     NaN  \n",
       "\n",
       "[5 rows x 774 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_with_features[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 6 extra feautres in addition to embedding dimensions in the file: number, gender, lemma, pos, tense,\n",
    "# person\n",
    "feature_col_count = 6\n",
    "\n",
    "# Feature to investigate in this notebook\n",
    "feature = 'Number'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da06780",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d134",
   "metadata": {},
   "source": [
    "1. Exclude datapoints with undefined feature values (e.g. Gender = `invariable`)\n",
    "2. Encode a grammatical feature as binary (e.g. Gender = 0 if masculine and 1 if feminine) (feature vector)\n",
    "3. Shuffle the data set\n",
    "4. Separate the dataset into 80% \"training\" and 20% test data\n",
    "5. For each dimension in the test dataset measure if the dimension values are dependent on the grammatic feature\n",
    "* Using [ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html): The data is split into 2 samples, all dimension values when the grammatical feature is 0 and when it's equal to 1.\n",
    "* Using [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "6. For each dimension highlighted during step #5 find medians for 2 subgroups: when the grammatical feature == 0 and when it == 1.\n",
    "7. For each word in the test dataset, find the predicted label using MAE using medians of the dimensions from #6.\n",
    "8. Compute accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bbb6b",
   "metadata": {},
   "source": [
    "We assume that achieved accuracies can be an efficient way of comparing the quality of grammatical information encoding in the word embeddings.\n",
    "\n",
    "The experiments for `Gender` and `Number` will be performed for \"nouns only\", \"adjectives only\" and \"nouns and adjectives\" combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a760",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99bc1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start the experiment with nouns only\n",
    "pos = ['NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b07b0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noun_train = []\n",
    "y_noun_train = []\n",
    "\n",
    "X_noun_test = []\n",
    "y_noun_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70563c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.Number != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_noun_train.append(xtr)\n",
    "    X_noun_test.append(xtst)\n",
    "    \n",
    "    y_noun_train.append(ytr)\n",
    "    y_noun_test.append(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ddfb0",
   "metadata": {},
   "source": [
    "### Compute ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eed918",
   "metadata": {},
   "source": [
    "We split each dimension into 2 samples: feminine nouns and masculine nouns. ANOVA test is used to assess if the population means are the same.\n",
    "\n",
    "If the population means are not the same, we can make an assumption that the gender information affects the distribution of values in the given dimension.\n",
    "\n",
    "If p-value < 0.001, reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3596e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73edb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2cc630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_noun_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims.append(model_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5b5d3",
   "metadata": {},
   "source": [
    "We can see that a very large amount of dimensions appear to be highlighted by the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1d86239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "Total dimensions 512\n",
      "ANOVA dimensions: 395\n",
      "\n",
      "flau_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 357\n",
      "\n",
      "flau_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 491\n",
      "\n",
      "flau_large_c:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 851\n",
      "\n",
      "cam_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 26\n",
      "\n",
      "xlm_large:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 245\n",
      "\n",
      "xlm_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 77\n",
      "\n",
      "bert_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 617\n",
      "\n",
      "distilbert_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 329\n",
      "\n",
      "bert_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}:\\nTotal dimensions {len(X_noun_train[i].columns)}\\nANOVA dimensions: {len(anova_dims[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867da94",
   "metadata": {},
   "source": [
    "### Compute Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488513e3",
   "metadata": {},
   "source": [
    "If mutual information is 0, we can consider that a given dimension is independent from Gender information.\n",
    "\n",
    "If MI > 0, we can't consider the dimension completely independent and it could encode the Gender information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad7be602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "455215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_noun_train[i], y_noun_train[i], discrete_features=[False]*len(X_noun_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a327f1f",
   "metadata": {},
   "source": [
    "Overall, threshold of 0 finds much more dimensions. This could be potentially addressed with a different threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b05902a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "    Total dimensions 512\n",
      "    ANOVA dimensions: 395\n",
      "    Mutual Information dimension: 370\n",
      "\n",
      "\n",
      "flau_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 357\n",
      "    Mutual Information dimension: 430\n",
      "\n",
      "\n",
      "flau_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 491\n",
      "    Mutual Information dimension: 523\n",
      "\n",
      "\n",
      "flau_large_c:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 851\n",
      "    Mutual Information dimension: 804\n",
      "\n",
      "\n",
      "cam_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 26\n",
      "    Mutual Information dimension: 386\n",
      "\n",
      "\n",
      "xlm_large:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 245\n",
      "    Mutual Information dimension: 620\n",
      "\n",
      "\n",
      "xlm_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 77\n",
      "    Mutual Information dimension: 353\n",
      "\n",
      "\n",
      "bert_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 617\n",
      "    Mutual Information dimension: 695\n",
      "\n",
      "\n",
      "distilbert_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 329\n",
      "    Mutual Information dimension: 531\n",
      "\n",
      "\n",
      "bert_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 0\n",
      "    Mutual Information dimension: 487\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f\"\"\"{models[i]['label']}:\n",
    "    Total dimensions {len(X_noun_train[i].columns)}\n",
    "    ANOVA dimensions: {len(anova_dims[i])}\n",
    "    Mutual Information dimension: {len(mi_dims[i])}\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af43dc",
   "metadata": {},
   "source": [
    "For now, for each model we select only dimensions that are potentially dependent on the gender information and found by the both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d64f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims = [set(anova_dims[i]).intersection(mi_dims[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a713",
   "metadata": {},
   "source": [
    "Final number of dimensions that we can consider not independent from the gender information for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dae8ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 308\n",
      "flau_base_u: 217\n",
      "flau_base_c: 375\n",
      "flau_large_c: 708\n",
      "cam_base: 13\n",
      "xlm_large: 175\n",
      "xlm_base: 39\n",
      "bert_base_u: 564\n",
      "distilbert_base: 253\n",
      "bert_base_c: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666804dc",
   "metadata": {},
   "source": [
    "### Compute medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb86617",
   "metadata": {},
   "source": [
    "We can try making predictions using the following dimensions:\n",
    "- All dimensions of WE (as the baseline)\n",
    "- Using the dimensions found in the ANOVA test\n",
    "- Using the dimensions found in the Mutual Information test\n",
    "- Using dimensions found in the both test\n",
    "\n",
    "To make such predictions we will:\n",
    "- Compute medians of class 1 and class 0 using only selected dimensions\n",
    "- For each word in the test set compute its label by finding MAE in comparison to the the median\n",
    "- Assign the label of the class with the smallest MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07503183",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cfc73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1].median()\n",
    "    medians_all.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2116a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_anova = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1909f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(anova_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(anova_dims[i])].median()\n",
    "    medians_anova.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a3a282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_mi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "660d8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(mi_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(mi_dims[i])].median()\n",
    "    medians_mi.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d455579",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_combined = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a088ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(mi_annova_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(mi_annova_dims[i])].median()\n",
    "    medians_combined.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d276c5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_0</th>\n",
       "      <th>median_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.484909</td>\n",
       "      <td>0.494005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.440108</td>\n",
       "      <td>0.442751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.498378</td>\n",
       "      <td>0.480110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.457846</td>\n",
       "      <td>0.476440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.529876</td>\n",
       "      <td>0.543103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.543586</td>\n",
       "      <td>0.548633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.521876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.464503</td>\n",
       "      <td>0.444439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.499523</td>\n",
       "      <td>0.506169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.539830</td>\n",
       "      <td>0.535725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     median_0  median_1\n",
       "252  0.484909  0.494005\n",
       "382  0.440108  0.442751\n",
       "402  0.498378  0.480110\n",
       "391  0.457846  0.476440\n",
       "396  0.529876  0.543103\n",
       "..        ...       ...\n",
       "710  0.543586  0.548633\n",
       "503  0.523560  0.521876\n",
       "15   0.464503  0.444439\n",
       "642  0.499523  0.506169\n",
       "387  0.539830  0.535725\n",
       "\n",
       "[217 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians_combined[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe5f06",
   "metadata": {},
   "source": [
    "### Predict label for test set using MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ae32713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4749af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mae0 = X_noun_test[i].apply(lambda x: mean_absolute_error(medians_all[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_noun_test[i].apply(lambda x: mean_absolute_error(medians_all[i]['median_1'], x), axis=1)\n",
    "    # If MAE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_all.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "805467a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_anova = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3e10e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mae0 = X_noun_test[i][list(anova_dims[i])].apply(lambda x: mean_absolute_error(medians_anova[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_noun_test[i][list(anova_dims[i])].apply(lambda x: mean_absolute_error(medians_anova[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_anova.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0670bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_mi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa692a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mae0 = X_noun_test[i][list(mi_dims[i])].apply(lambda x: mean_absolute_error(medians_mi[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_noun_test[i][list(mi_dims[i])].apply(lambda x: mean_absolute_error(medians_mi[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_mi.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56784409",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_combined = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fa9a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mae0 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians_combined[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians_combined[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_combined.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44bc8",
   "metadata": {},
   "source": [
    "### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cd7c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_noun_df = pd.DataFrame(columns=['All dims', 'ANOVA dims', 'MI dims', 'Combined dims'], index=[m['label'] for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfe64b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    accs_noun_df.loc[models[i]['label'], 'All dims'] = accuracy_score(y_noun_test[i], y_preds_all[i])\n",
    "    \n",
    "    if any(y_preds_anova[i]):\n",
    "        accs_noun_df.loc[models[i]['label'], 'ANOVA dims'] = accuracy_score(y_noun_test[i], y_preds_anova[i])\n",
    "    else: \n",
    "        accs_noun_df.loc[models[i]['label'], 'ANOVA dims'] = 0\n",
    "    \n",
    "    if any(y_preds_mi[i]):\n",
    "        accs_noun_df.loc[models[i]['label'], 'MI dims'] = accuracy_score(y_noun_test[i], y_preds_mi[i])\n",
    "    else:\n",
    "        accs_noun_df.loc[models[i]['label'], 'MI dims'] = 0\n",
    "    \n",
    "    if any(y_preds_combined[i]):\n",
    "        accs_noun_df.loc[models[i]['label'], 'Combined dims'] = accuracy_score(y_noun_test[i], y_preds_combined[i])\n",
    "    else:\n",
    "        accs_noun_df.loc[models[i]['label'], 'Combined dims'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a5128ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All dims</th>\n",
       "      <th>ANOVA dims</th>\n",
       "      <th>MI dims</th>\n",
       "      <th>Combined dims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flau_small_c</th>\n",
       "      <td>0.901748</td>\n",
       "      <td>0.901748</td>\n",
       "      <td>0.905365</td>\n",
       "      <td>0.90657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_u</th>\n",
       "      <td>0.62064</td>\n",
       "      <td>0.614826</td>\n",
       "      <td>0.616764</td>\n",
       "      <td>0.610465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_base_c</th>\n",
       "      <td>0.635322</td>\n",
       "      <td>0.640747</td>\n",
       "      <td>0.648583</td>\n",
       "      <td>0.649789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flau_large_c</th>\n",
       "      <td>0.942737</td>\n",
       "      <td>0.941531</td>\n",
       "      <td>0.940928</td>\n",
       "      <td>0.940325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cam_base</th>\n",
       "      <td>0.661858</td>\n",
       "      <td>0.641118</td>\n",
       "      <td>0.661858</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_large</th>\n",
       "      <td>0.549898</td>\n",
       "      <td>0.564155</td>\n",
       "      <td>0.547862</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm_base</th>\n",
       "      <td>0.543788</td>\n",
       "      <td>0.564155</td>\n",
       "      <td>0.543788</td>\n",
       "      <td>0.566191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_u</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert_base</th>\n",
       "      <td>0.627486</td>\n",
       "      <td>0.631103</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>0.640145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_base_c</th>\n",
       "      <td>0.560579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 All dims ANOVA dims   MI dims Combined dims\n",
       "flau_small_c     0.901748   0.901748  0.905365       0.90657\n",
       "flau_base_u       0.62064   0.614826  0.616764      0.610465\n",
       "flau_base_c      0.635322   0.640747  0.648583      0.649789\n",
       "flau_large_c     0.942737   0.941531  0.940928      0.940325\n",
       "cam_base         0.661858   0.641118  0.661858        0.5789\n",
       "xlm_large        0.549898   0.564155  0.547862      0.553971\n",
       "xlm_base         0.543788   0.564155  0.543788      0.566191\n",
       "bert_base_u         0.512      0.512     0.512         0.512\n",
       "distilbert_base  0.627486   0.631103  0.629295      0.640145\n",
       "bert_base_c      0.560579          0  0.564195             0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs_noun_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304fd3f",
   "metadata": {},
   "source": [
    "# Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fd2f3",
   "metadata": {},
   "source": [
    "Repeat all steps but for adjectives only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a9c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d031f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adj_train = []\n",
    "y_adj_train = []\n",
    "\n",
    "X_adj_test = []\n",
    "y_adj_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f3d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.Number != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_adj_train.append(xtr)\n",
    "    X_adj_test.append(xtst)\n",
    "    \n",
    "    y_adj_train.append(ytr)\n",
    "    y_adj_test.append(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00d5a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2835afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_adj_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_adj.append(model_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6290e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53b8ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_adj_train[i], y_adj_train[i], discrete_features=[False]*len(X_adj_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_adj.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1c839f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims_adj = [set(anova_dims_adj[i]).intersection(mi_dims_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bffdb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 232\n",
      "flau_base_u: 83\n",
      "flau_base_c: 217\n",
      "flau_large_c: 535\n",
      "cam_base: 107\n",
      "xlm_large: 15\n",
      "xlm_base: 0\n",
      "bert_base_u: 58\n",
      "distilbert_base: 70\n",
      "bert_base_c: 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims_adj[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea17643",
   "metadata": {},
   "source": [
    "### Computing medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5a3dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77c05ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1].median()\n",
    "    medians_adj_all.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85cb3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj_anova = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b14e78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(anova_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(anova_dims_adj[i])].median()\n",
    "    medians_adj_anova.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68b65ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj_mi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e375583",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(mi_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(mi_dims_adj[i])].median()\n",
    "    medians_adj_mi.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43d36058",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj_combined = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecc2ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_adj_combined.append(medians_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db8d233",
   "metadata": {},
   "source": [
    "### Computing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f21b0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_adj_all = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_adj_test[i].apply(lambda x: mean_absolute_error(medians_adj_all[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_adj_test[i].apply(lambda x: mean_absolute_error(medians_adj_all[i]['median_1'], x), axis=1)\n",
    "    # If MAE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_adj_all.append(y_pred)\n",
    "\n",
    "y_preds_adj_anova = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_adj_test[i][list(anova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_anova[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_adj_test[i][list(anova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_anova[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_adj_anova.append(y_pred)\n",
    "\n",
    "y_preds_adj_mi = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_adj_test[i][list(mi_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_mi[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_adj_test[i][list(mi_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_mi[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_adj_mi.append(y_pred)\n",
    "\n",
    "y_preds_adj_combined = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_combined[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj_combined[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_adj_combined.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "842c4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj_df = pd.DataFrame(columns=['All dims', 'ANOVA dims', 'MI dims', 'Combined dims'], index=[m['label'] for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0baeff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    accs_adj_df.loc[models[i]['label'], 'All dims'] = accuracy_score(y_adj_test[i], y_preds_adj_all[i])\n",
    "    \n",
    "    if any(y_preds_adj_anova[i]):\n",
    "        accs_adj_df.loc[models[i]['label'], 'ANOVA dims'] = accuracy_score(y_adj_test[i], y_preds_adj_anova[i])\n",
    "    else: \n",
    "        accs_adj_df.loc[models[i]['label'], 'ANOVA dims'] = 0\n",
    "    \n",
    "    if any(y_preds_adj_mi[i]):\n",
    "        accs_adj_df.loc[models[i]['label'], 'MI dims'] = accuracy_score(y_adj_test[i], y_preds_adj_mi[i])\n",
    "    else:\n",
    "        accs_adj_df.loc[models[i]['label'], 'MI dims'] = 0\n",
    "    \n",
    "    if any(y_preds_adj_combined[i]):\n",
    "        accs_adj_df.loc[models[i]['label'], 'Combined dims'] = accuracy_score(y_adj_test[i], y_preds_adj_combined[i])\n",
    "    else:\n",
    "        accs_adj_df.loc[models[i]['label'], 'Combined dims'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91257f",
   "metadata": {},
   "source": [
    "Here are the accuracies for adjectives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfeb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8bff8",
   "metadata": {},
   "source": [
    "# Adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d932b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 332\n",
      "flau_base_u: 260\n",
      "flau_base_c: 403\n",
      "flau_large_c: 725\n",
      "cam_base: 7\n",
      "xlm_large: 188\n",
      "xlm_base: 36\n",
      "bert_base_u: 579\n",
      "distilbert_base: 286\n",
      "bert_base_c: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [393, 299]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m y_preds_na_anova \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models)):\n\u001b[0;32m---> 92\u001b[0m     mae0 \u001b[38;5;241m=\u001b[39m \u001b[43mX_na_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manova_dims_adj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedians_na_anova\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedian_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     mae1 \u001b[38;5;241m=\u001b[39m X_na_test[i][\u001b[38;5;28mlist\u001b[39m(anova_dims_adj[i])]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: mean_absolute_error(medians_na_anova[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_1\u001b[39m\u001b[38;5;124m'\u001b[39m], x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     89\u001b[0m y_preds_na_anova \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models)):\n\u001b[0;32m---> 92\u001b[0m     mae0 \u001b[38;5;241m=\u001b[39m X_na_test[i][\u001b[38;5;28mlist\u001b[39m(anova_dims_adj[i])]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedians_na_anova\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedian_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m     mae1 \u001b[38;5;241m=\u001b[39m X_na_test[i][\u001b[38;5;28mlist\u001b[39m(anova_dims_adj[i])]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: mean_absolute_error(medians_na_anova[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_1\u001b[39m\u001b[38;5;124m'\u001b[39m], x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:204\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    141\u001b[0m     {\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m ):\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    208\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    101\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [393, 299]"
     ]
    }
   ],
   "source": [
    "pos = ['ADJ', 'NOUN']\n",
    "\n",
    "X_na_train = []\n",
    "y_na_train = []\n",
    "\n",
    "X_na_test = []\n",
    "y_na_test = []\n",
    "\n",
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we[(we.Gender != 'invariable') & (we.Number != 'invariable') & (we.POS.isin(pos))],\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          encode=True,\n",
    "                                          split=True)\n",
    "    X_na_train.append(xtr)\n",
    "    X_na_test.append(xtst)\n",
    "    \n",
    "    y_na_train.append(ytr)\n",
    "    y_na_test.append(ytst)\n",
    "\n",
    "anova_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_adj_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_na_train[i][dim], y_na_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_na.append(model_dims)\n",
    "\n",
    "mi_dims_na = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_na_train[i], y_na_train[i], discrete_features=[False]*len(X_na_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_na.append(non_indep_dims)\n",
    "\n",
    "mi_annova_dims_na = [set(anova_dims_na[i]).intersection(mi_dims_na[i]) for i in range(len(models))]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims_na[i])}')\n",
    "\n",
    "### Computing medians\n",
    "\n",
    "medians_na_all = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1].median()\n",
    "    medians_na_all.append(medians_df)\n",
    "\n",
    "medians_na_anova = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0][list(anova_dims_na[i])].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1][list(anova_dims_na[i])].median()\n",
    "    medians_na_anova.append(medians_df)\n",
    "\n",
    "medians_na_mi = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0][list(mi_dims_na[i])].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1][list(mi_dims_na[i])].median()\n",
    "    medians_na_mi.append(medians_df)\n",
    "\n",
    "medians_na_combined = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_na_train[i][y_na_train[i] == 0][list(mi_annova_dims_na[i])].median()\n",
    "    medians_df['median_1'] = X_na_train[i][y_na_train[i] == 1][list(mi_annova_dims_na[i])].median()\n",
    "    medians_na_combined.append(medians_df)\n",
    "\n",
    "### Computing predictions\n",
    "\n",
    "y_preds_na_all = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_na_test[i].apply(lambda x: mean_absolute_error(medians_na_all[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_na_test[i].apply(lambda x: mean_absolute_error(medians_na_all[i]['median_1'], x), axis=1)\n",
    "    # If MAE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_na_all.append(y_pred)\n",
    "\n",
    "y_preds_na_anova = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_na_test[i][list(anova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_anova[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_na_test[i][list(anova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_anova[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_na_anova.append(y_pred)\n",
    "\n",
    "y_preds_na_mi = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_na_test[i][list(mi_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_mi[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_na_test[i][list(mi_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_mi[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_na_mi.append(y_pred)\n",
    "\n",
    "y_preds_na_combined = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mae0 = X_na_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_combined[i]['median_0'], x), axis=1)\n",
    "    mae1 = X_na_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_na_combined[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mae0 > mae1).apply(int)\n",
    "    y_preds_na_combined.append(y_pred)\n",
    "\n",
    "accs_na_df = pd.DataFrame(columns=['All dims', 'ANOVA dims', 'MI dims', 'Combined dims'], index=[m['label'] for m in models])\n",
    "\n",
    "for i in range(len(models)):\n",
    "    accs_na_df.loc[models[i]['label'], 'All dims'] = accuracy_score(y_na_test[i], y_preds_na_all[i])\n",
    "    \n",
    "    if any(y_preds_adj_anova[i]):\n",
    "        accs_na_df.loc[models[i]['label'], 'ANOVA dims'] = accuracy_score(y_na_test[i], y_preds_na_anova[i])\n",
    "    else: \n",
    "        accs_na_df.loc[models[i]['label'], 'ANOVA dims'] = 0\n",
    "    \n",
    "    if any(y_preds_adj_mi[i]):\n",
    "        accs_na_df.loc[models[i]['label'], 'MI dims'] = accuracy_score(y_na_test[i], y_preds_na_mi[i])\n",
    "    else:\n",
    "        accs_na_df.loc[models[i]['label'], 'MI dims'] = 0\n",
    "    \n",
    "    if any(y_preds_adj_combined[i]):\n",
    "        accs_na_df.loc[models[i]['label'], 'Combined dims'] = accuracy_score(y_na_test[i], y_preds_na_combined[i])\n",
    "    else:\n",
    "        accs_adj_df.loc[models[i]['label'], 'Combined dims'] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
