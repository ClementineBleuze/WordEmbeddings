{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac006e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f48d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preparation import prepare_dataset, read_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd6ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e895408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b537ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b74df3",
   "metadata": {},
   "source": [
    "Due to big size of WE files they are not uploaded to Github, but can instead be downloaded [here](https://drive.google.com/drive/folders/10Ea62GRlq4t7bq-nK9tPtYFu0kbCciey?usp=sharing).\n",
    "\n",
    "The code below expects a folder \"Data\" in the root folder containing all the information from the Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8faf03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_small_cased',\n",
    "        'label': 'flau_small_c'\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'name': 'flaubert/flaubert_base_uncased', \n",
    "        'label': 'flau_base_u'\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_base_cased',\n",
    "        'label': 'flau_base_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'flaubert/flaubert_large_cased',\n",
    "        'label': 'flau_large_c'\n",
    "    },\n",
    "    {\n",
    "        'name': 'camembert/camembert-base',\n",
    "        'label': 'cam_base'\n",
    "    }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [m['label'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba233d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_with_features = read_datasets(\n",
    "                            path = '../Data',\n",
    "                            model_labels = labels,\n",
    "                            file_name = 'all_unique_pos_we.csv'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f8b99",
   "metadata": {},
   "source": [
    "We want to encode POS information as binary for 3 experiments:\n",
    "- For the noun POS information test: nouns encoded as 1, adjectives and verbs as 0\n",
    "- For the verb POS information test: verbs encoded as 1, adjectives and nouns as 0\n",
    "- For the adjective POS text: adjectives encoded as 1, verbs and nouns as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091c3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word\n",
       "2D           0\n",
       "3D           0\n",
       "aa           0\n",
       "aba          0\n",
       "abaisse      0\n",
       "            ..\n",
       "évidentes    1\n",
       "évolutif     1\n",
       "évolutive    1\n",
       "évoquée      1\n",
       "évoquées     1\n",
       "Name: POS, Length: 14883, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(we_with_features[0].POS == 'ADJ').apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2dec133",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in we_with_features:\n",
    "    df['is_noun'] = (df.POS == 'NOUN').apply(int)\n",
    "    df['is_verb'] = (df.POS == 'VERB').apply(int)\n",
    "    df['is_adj'] = (df.POS == 'ADJ').apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6afc6c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>511</th>\n",
       "      <th>Number</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Person</th>\n",
       "      <th>is_noun</th>\n",
       "      <th>is_verb</th>\n",
       "      <th>is_adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D</th>\n",
       "      <td>5.531172</td>\n",
       "      <td>-8.963815</td>\n",
       "      <td>1.558320</td>\n",
       "      <td>3.143550</td>\n",
       "      <td>-5.372142</td>\n",
       "      <td>-0.174002</td>\n",
       "      <td>-1.124767</td>\n",
       "      <td>5.729996</td>\n",
       "      <td>-2.367389</td>\n",
       "      <td>4.247167</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.613951</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>2D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>3.969331</td>\n",
       "      <td>-6.442656</td>\n",
       "      <td>1.451928</td>\n",
       "      <td>3.447791</td>\n",
       "      <td>-4.224664</td>\n",
       "      <td>-1.029557</td>\n",
       "      <td>-3.664733</td>\n",
       "      <td>4.911453</td>\n",
       "      <td>0.223902</td>\n",
       "      <td>5.621365</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.951385</td>\n",
       "      <td>invariable</td>\n",
       "      <td>feminine</td>\n",
       "      <td>3D</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>5.617864</td>\n",
       "      <td>-6.741737</td>\n",
       "      <td>2.519838</td>\n",
       "      <td>-3.914263</td>\n",
       "      <td>2.801907</td>\n",
       "      <td>-1.182259</td>\n",
       "      <td>4.435670</td>\n",
       "      <td>-1.600746</td>\n",
       "      <td>-0.582458</td>\n",
       "      <td>1.409745</td>\n",
       "      <td>...</td>\n",
       "      <td>2.984729</td>\n",
       "      <td>invariable</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aa</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aba</th>\n",
       "      <td>4.914313</td>\n",
       "      <td>-6.923126</td>\n",
       "      <td>-3.848757</td>\n",
       "      <td>5.110574</td>\n",
       "      <td>-2.516107</td>\n",
       "      <td>-4.938292</td>\n",
       "      <td>2.373581</td>\n",
       "      <td>-2.756590</td>\n",
       "      <td>2.567556</td>\n",
       "      <td>2.412183</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.154819</td>\n",
       "      <td>singular</td>\n",
       "      <td>masculine</td>\n",
       "      <td>aba</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaisse</th>\n",
       "      <td>4.652038</td>\n",
       "      <td>-4.028066</td>\n",
       "      <td>0.883200</td>\n",
       "      <td>4.782077</td>\n",
       "      <td>-2.294614</td>\n",
       "      <td>-3.894452</td>\n",
       "      <td>-0.810279</td>\n",
       "      <td>-0.713935</td>\n",
       "      <td>4.819910</td>\n",
       "      <td>4.090150</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.836028</td>\n",
       "      <td>singular</td>\n",
       "      <td>feminine</td>\n",
       "      <td>abaisse</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "Word                                                                            \n",
       "2D       5.531172 -8.963815  1.558320  3.143550 -5.372142 -0.174002 -1.124767   \n",
       "3D       3.969331 -6.442656  1.451928  3.447791 -4.224664 -1.029557 -3.664733   \n",
       "aa       5.617864 -6.741737  2.519838 -3.914263  2.801907 -1.182259  4.435670   \n",
       "aba      4.914313 -6.923126 -3.848757  5.110574 -2.516107 -4.938292  2.373581   \n",
       "abaisse  4.652038 -4.028066  0.883200  4.782077 -2.294614 -3.894452 -0.810279   \n",
       "\n",
       "                7         8         9  ...       511      Number     Gender  \\\n",
       "Word                                   ...                                    \n",
       "2D       5.729996 -2.367389  4.247167  ... -4.613951  invariable   feminine   \n",
       "3D       4.911453  0.223902  5.621365  ... -2.951385  invariable   feminine   \n",
       "aa      -1.600746 -0.582458  1.409745  ...  2.984729  invariable  masculine   \n",
       "aba     -2.756590  2.567556  2.412183  ... -4.154819    singular  masculine   \n",
       "abaisse -0.713935  4.819910  4.090150  ... -1.836028    singular   feminine   \n",
       "\n",
       "           Lemma   POS  Tense  Person  is_noun  is_verb  is_adj  \n",
       "Word                                                             \n",
       "2D            2D  NOUN    NaN     NaN        1        0       0  \n",
       "3D            3D  NOUN    NaN     NaN        1        0       0  \n",
       "aa            aa  NOUN    NaN     NaN        1        0       0  \n",
       "aba          aba  NOUN    NaN     NaN        1        0       0  \n",
       "abaisse  abaisse  NOUN    NaN     NaN        1        0       0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_with_features[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b413ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 9 extra feautres in addition to embedding dimensions in the file: number, gender, lemma, pos, tense,\n",
    "# person, is_noun, is_verb, is_adj\n",
    "feature_col_count = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da06780",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d134",
   "metadata": {},
   "source": [
    "1. Exclude datapoints with undefined feature values (e.g. Gender = `invariable`)\n",
    "2. Encode a grammatical feature as binary (e.g. Gender = 0 if masculine and 1 if feminine) (feature vector)\n",
    "3. Shuffle the data set\n",
    "4. Separate the dataset into 80% \"training\" and 20% test data\n",
    "5. For each dimension in the test dataset measure if the dimension values are dependent on the grammatic feature\n",
    "* Using [ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html): The data is split into 2 samples, all dimension values when the grammatical feature is 0 and when it's equal to 1.\n",
    "* Using [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "6. For each dimension highlighted during step #5 find medians for 2 subgroups: when the grammatical feature == 0 and when it == 1.\n",
    "7. For each word in the test dataset, find the predicted label using MSE using medians of the dimensions from #6.\n",
    "8. Compute accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bbb6b",
   "metadata": {},
   "source": [
    "We assume that achieved accuracies can be an efficient way of comparing the quality of grammatical information encoding in the word embeddings.\n",
    "\n",
    "The experiments for `Gender` and `Number` will be performed for \"nouns only\", \"adjectives only\" and \"nouns and adjectives\" combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a760",
   "metadata": {},
   "source": [
    "# Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb95279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature to investigate in this notebook\n",
    "feature = 'is_noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b07b0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noun_train = []\n",
    "y_noun_train = []\n",
    "\n",
    "X_noun_test = []\n",
    "y_noun_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70563c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we,\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          split=True)\n",
    "    X_noun_train.append(xtr)\n",
    "    X_noun_test.append(xtst)\n",
    "    \n",
    "    y_noun_train.append(ytr)\n",
    "    y_noun_test.append(ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ddfb0",
   "metadata": {},
   "source": [
    "### Compute ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eed918",
   "metadata": {},
   "source": [
    "We split each dimension into 2 samples: feminine nouns and masculine nouns. ANOVA test is used to assess if the population means are the same.\n",
    "\n",
    "If the population means are not the same, we can make an assumption that the gender information affects the distribution of values in the given dimension.\n",
    "\n",
    "If p-value < 0.001, reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3596e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73edb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2cc630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_noun_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_noun_train[i][dim], y_noun_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims.append(model_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5b5d3",
   "metadata": {},
   "source": [
    "We can see that a very large amount of dimensions appear to be highlighted by the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1d86239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "Total dimensions 512\n",
      "ANOVA dimensions: 432\n",
      "\n",
      "flau_base_u:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 552\n",
      "\n",
      "flau_base_c:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 503\n",
      "\n",
      "flau_large_c:\n",
      "Total dimensions 1024\n",
      "ANOVA dimensions: 835\n",
      "\n",
      "cam_base:\n",
      "Total dimensions 768\n",
      "ANOVA dimensions: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}:\\nTotal dimensions {len(X_noun_train[i].columns)}\\nANOVA dimensions: {len(anova_dims[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867da94",
   "metadata": {},
   "source": [
    "### Compute Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488513e3",
   "metadata": {},
   "source": [
    "If mutual information is 0, we can consider that a given dimension is independent from POS information.\n",
    "\n",
    "If MI > 0, we can't consider the dimension completely independent and it could encode the POS information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad7be602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "455215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_noun_train[i], y_noun_train[i], discrete_features=[False]*len(X_noun_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a327f1f",
   "metadata": {},
   "source": [
    "Overall, threshold of 0 finds much more dimensions. This could be potentially addressed with a different threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b05902a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c:\n",
      "    Total dimensions 512\n",
      "    ANOVA dimensions: 432\n",
      "    Mutual Information dimension: 427\n",
      "\n",
      "\n",
      "flau_base_u:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 552\n",
      "    Mutual Information dimension: 768\n",
      "\n",
      "\n",
      "flau_base_c:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 503\n",
      "    Mutual Information dimension: 559\n",
      "\n",
      "\n",
      "flau_large_c:\n",
      "    Total dimensions 1024\n",
      "    ANOVA dimensions: 835\n",
      "    Mutual Information dimension: 872\n",
      "\n",
      "\n",
      "cam_base:\n",
      "    Total dimensions 768\n",
      "    ANOVA dimensions: 100\n",
      "    Mutual Information dimension: 432\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f\"\"\"{models[i]['label']}:\n",
    "    Total dimensions {len(X_noun_train[i].columns)}\n",
    "    ANOVA dimensions: {len(anova_dims[i])}\n",
    "    Mutual Information dimension: {len(mi_dims[i])}\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af43dc",
   "metadata": {},
   "source": [
    "For now, for each model we select only dimensions that are potentially dependent on the gender information and found by the both tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d64f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims = [set(anova_dims[i]).intersection(mi_dims[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2a713",
   "metadata": {},
   "source": [
    "Final number of dimensions that we can consider not independent from the gender information for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dae8ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: 384\n",
      "flau_base_u: 552\n",
      "flau_base_c: 394\n",
      "flau_large_c: 752\n",
      "cam_base: 61\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: {len(mi_annova_dims[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666804dc",
   "metadata": {},
   "source": [
    "### Compute medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07503183",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cfc73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_noun_train[i][y_noun_train[i] == 0][list(mi_annova_dims[i])].median()\n",
    "    medians_df['median_1'] = X_noun_train[i][y_noun_train[i] == 1][list(mi_annova_dims[i])].median()\n",
    "    medians.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d276c5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_0</th>\n",
       "      <th>median_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.600646</td>\n",
       "      <td>0.512569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.496572</td>\n",
       "      <td>0.451101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.525901</td>\n",
       "      <td>0.509614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.584902</td>\n",
       "      <td>0.493335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.534789</td>\n",
       "      <td>0.552056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.450956</td>\n",
       "      <td>0.477892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.549268</td>\n",
       "      <td>0.590075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.505178</td>\n",
       "      <td>0.529084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.389550</td>\n",
       "      <td>0.432775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.651416</td>\n",
       "      <td>0.547323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     median_0  median_1\n",
       "310  0.600646  0.512569\n",
       "178  0.496572  0.451101\n",
       "450  0.525901  0.509614\n",
       "305  0.584902  0.493335\n",
       "109  0.534789  0.552056\n",
       "..        ...       ...\n",
       "488  0.450956  0.477892\n",
       "478  0.549268  0.590075\n",
       "283  0.505178  0.529084\n",
       "209  0.389550  0.432775\n",
       "401  0.651416  0.547323\n",
       "\n",
       "[384 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe5f06",
   "metadata": {},
   "source": [
    "### Predict label for test set using MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ae32713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4749af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_noun_test[i][list(mi_annova_dims[i])].apply(lambda x: mean_absolute_error(medians[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab44bc8",
   "metadata": {},
   "source": [
    "### Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a5128ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.8558951965065502\n",
      "flau_base_u: Accuracy 0.6657549234135668\n",
      "flau_base_c: Accuracy 0.5754114880752436\n",
      "flau_large_c: Accuracy 0.8538797447094391\n",
      "cam_base: Accuracy 0.4769071094966269\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_noun_test[i], y_preds[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304fd3f",
   "metadata": {},
   "source": [
    "# Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fd2f3",
   "metadata": {},
   "source": [
    "Repeat all steps but for adjectives only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a9c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'is_adj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d031f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adj_train = []\n",
    "y_adj_train = []\n",
    "\n",
    "X_adj_test = []\n",
    "y_adj_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f3d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we,\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          split=True)\n",
    "    X_adj_train.append(xtr)\n",
    "    X_adj_test.append(xtst)\n",
    "    \n",
    "    y_adj_train.append(ytr)\n",
    "    y_adj_test.append(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00d5a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2835afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_adj_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_adj_train[i][dim], y_adj_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_adj.append(model_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6290e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_dims_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53b8ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_adj_train[i], y_adj_train[i], discrete_features=[False]*len(X_adj_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_adj.append(non_indep_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1c839f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_annova_dims_adj = [set(anova_dims_adj[i]).intersection(mi_dims_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d56f9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecc2ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_adj_train[i][y_adj_train[i] == 0][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_df['median_1'] = X_adj_train[i][y_adj_train[i] == 1][list(mi_annova_dims_adj[i])].median()\n",
    "    medians_adj.append(medians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c439ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_adj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac68a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    mse0 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_adj_test[i][list(mi_annova_dims_adj[i])].apply(lambda x: mean_absolute_error(medians_adj[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_adj.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c92fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91257f",
   "metadata": {},
   "source": [
    "Here are the accuracies for adjectives only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d274799",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_adj = [accuracy_score(y_adj_test[i], y_preds_adj[i]) for i in range(len(models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7dfeb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.8642929123278468\n",
      "flau_base_u: Accuracy 0.7169037199124726\n",
      "flau_base_c: Accuracy 0.611353711790393\n",
      "flau_large_c: Accuracy 0.8545515619751428\n",
      "cam_base: Accuracy 0.6875973015049299\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_adj_test[i], y_preds_adj[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8bff8",
   "metadata": {},
   "source": [
    "# Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d932b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flau_small_c: Accuracy 0.9089687604971448\n",
      "flau_base_u: Accuracy 0.7568380743982495\n",
      "flau_base_c: Accuracy 0.5945582801477998\n",
      "flau_large_c: Accuracy 0.8878065166274773\n",
      "cam_base: Accuracy 0.4193046185781007\n"
     ]
    }
   ],
   "source": [
    "feature = 'is_verb'\n",
    "\n",
    "X_v_train = []\n",
    "y_v_train = []\n",
    "\n",
    "X_v_test = []\n",
    "y_v_test = []\n",
    "\n",
    "for we in we_with_features:\n",
    "    xtr, xtst, ytr, ytst = prepare_dataset(dataset=we,\n",
    "                                          feature_col_count=feature_col_count,\n",
    "                                          feature_name=feature,\n",
    "                                          split=True)\n",
    "    X_v_train.append(xtr)\n",
    "    X_v_test.append(xtst)\n",
    "    \n",
    "    y_v_train.append(ytr)\n",
    "    y_v_test.append(ytst)\n",
    "\n",
    "anova_dims_v = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model_dims = []\n",
    "    for dim in X_v_train[i].columns:\n",
    "        sample1 = [x[0] for x in zip(X_v_train[i][dim], y_v_train[i]) if x[1] == 0]\n",
    "        sample2 = [x[0] for x in zip(X_v_train[i][dim], y_v_train[i]) if x[1] == 1]\n",
    "        if f_oneway(sample1, sample2).pvalue < pv_threshold:\n",
    "            model_dims.append(dim)\n",
    "    anova_dims_v.append(model_dims)\n",
    "\n",
    "mi_dims_v = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    res = mutual_info_classif(X_v_train[i], y_v_train[i], discrete_features=[False]*len(X_v_train[i].columns))\n",
    "    non_indep_dims = [str(x[0]) for x in np.argwhere(res > 0)]\n",
    "    mi_dims_v.append(non_indep_dims)\n",
    "\n",
    "mi_annova_dims_v = [set(anova_dims_v[i]).intersection(mi_dims_v[i]) for i in range(len(models))]\n",
    "\n",
    "medians_v = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    medians_df = pd.DataFrame(columns=['median_0', 'median_1'])\n",
    "    medians_df['median_0'] = X_v_train[i][y_v_train[i] == 0][list(mi_annova_dims_v[i])].median()\n",
    "    medians_df['median_1'] = X_v_train[i][y_v_train[i] == 1][list(mi_annova_dims_v[i])].median()\n",
    "    medians_v.append(medians_df)\n",
    "\n",
    "y_preds_v = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    mse0 = X_v_test[i][list(mi_annova_dims_v[i])].apply(lambda x: mean_absolute_error(medians_v[i]['median_0'], x), axis=1)\n",
    "    mse1 = X_v_test[i][list(mi_annova_dims_v[i])].apply(lambda x: mean_absolute_error(medians_v[i]['median_1'], x), axis=1)\n",
    "    # If MSE for sample 0 is lower than for sample 1, the label should be 0. So we need to convert False to 0.\n",
    "    y_pred = (mse0 > mse1).apply(int)\n",
    "    y_preds_v.append(y_pred)\n",
    "\n",
    "accs_v = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(f'{models[i][\"label\"]}: Accuracy {accuracy_score(y_v_test[i], y_preds_v[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330f3fa",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c415c6c",
   "metadata": {},
   "source": [
    "With this framework we can compare the quality of grammatical information encoding.\n",
    "\n",
    "From the results we can see that:\n",
    "* FlauBERT cased models appear to encode the gender information much better than the uncased model\n",
    "* FlauBERT large allows to achieve very high accuracy in segmentation feminine and masculine nouns and adjectives only based on the values of embedding dimensions\n",
    "* Despite much smaller size FlauBERT small achieves comparable classification accuracy with FlauBERT large for adjective genders, however, not for noun genders\n",
    "* CamemBERT classification results are close to random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526c1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe20378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
